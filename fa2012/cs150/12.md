Pipelining
==========
September 27, 2012
------------------
Last time, I just mentioned in passing that we will always be reading
32-bit instruction words in this class, but ARM has both 32- and 16-bit
instruction sets. MicroMIPS does the same thing.

Optimized for size rather than speed; will run at 100 MHz (not very good
compared to desktop microprocessors made in the same process, which run in
the gigahertz range), but it burns 3 mW. $0.06 \text{mm}^2$. Questions
about power monitor -- you've got a chip that's somehow hanging off of the
power plug and manages one way or the other to get a voltage and current
signal. You know the voltage is going to look like 155 amplitude.

Serial! Your serial line, the thing I want you to play around with is the
receiver. We give this to you in the lab, but the thing is I want you to
design the basic architecture.

Start, stop, some bits between. You've got a counter on here that's running
at 1024 ticks per bit of input. Eye diagrams.

Notion of factoring state machines. Or you can draw 10000 states if you
want.

Something about Kris + scanners, it always ends badly. Will be putting
lectures on the course website (and announce on Piazza). High-level, look
at pipelines.

MIPS pipeline

For sure, you should be reading 7.5, if you haven't already. H&H do a great
job. Slightly different way of looking at pipelines, which is probably
inferior, but it's different.

First off, suppose I've got something like my Golden Bear power monitor,
and $f = (A+B)C + D$. It's going to give me this ALU that does addition, ALU
that does multiplication, and then an ALU that does addition again, and
that will end up in my output register.

There is a critical path (how fast can I clock this thing?). For now,
assume "perfect" fast registers. This, however, is a bad assumption.

So let's talk about propagation delay in registers.

Timing & Delay (H&H 3.5; Fig 3.35,36)
-------------------------------------
Suppose I have a simple edge-triggered D flipflop, and these things come
with some specs on the input and output, and in particular, there is a
setup time ($t_{\mathrm{setup}}$) and a hold time ($t_{\mathrm{hold}}$).

On the FPGA, these are each like 0.4 ns, whereas in 22nm, these are more
like 10 ps.

And then the output is not going to change immediately (going to remain
constant for some period of time before it changes), $t_{ccq}$ is the
minimum time for clock to contamination (change) in Q. And then there's a
maximum called $t_{pcq}$, the maximum (worst-case) for clock to stable
Q. Just parameters that you can't control (aside from choosing a different
flipflop).

So what do we want to do? We want to combine these flipflops through some
combinational logic with some propagation delay ($t_{pd}$) and see what our
constraints are going to be on the timing.

Once the output is stable ($t_{pcq}$), it has to go through my
combinational logic ($t_{pd}$), and then counting backwards, I've got
$t_{setup}$, and that overall has to be less than my cycle. Tells you how
complex logic can be, and how many stages of pipelines you need. Part of
the story of selling microprocessors was clock speed. Some of the people
who got bachelors in EE cared, but people only really bought the higher
clock speeds. So there'd be like 4 NAND gate delays, and that was it. One
of the reasons why Intel machines have such incredibly deep pipelines:
everything was cut into pieces so they could have these clock speeds.

So. $t_{pd}$ on your Xilinx FPGA for block RAM, which you care about, is
something like 2 ns from clock to data. 32-bit adders are also on the order
of 2 ns. What you're likely to end up with is a 50 MHz part. I also have to
worry about fast combinational logic -- what happens as the rising edge
goes high, my new input contaminates, and it messes up this register before
the setup time? Therefore $t_{ccq} + t_{pd} > t_{hold}$, necessarily, so we
need $t_{ccq} > t_{hold}$ for a good flipflop (consider shift registers,
where we have basically no propagation delay).

Therefore $t_{pcq} + t_{setup} + t_{pd} < t_{cycle}$.

What does this have to do with the flipflop we know about? If we look at
the flipflop that we've done in the past (with inverters, controlled
buffers, etc), what is $t_{setup}$? We have several delays; $t_{setup}$
should ideally have D propagate to X and Y. How long is the hold
afterwards? You'd like $D$ to be constant for an inverter delay (so that it
can stop having an effect). That's pretty stable. $t_{hold}$ is something
like the delay of an inverter (if you want to be really safe, you'd say
twice that number). $t_{pcq}$, assuming we have valid setup, the D value
will be sitting on Y, and we've got two inverter delays, and $t_{ccq}$ is
also 2 inverter delays.

Good midterm-like question for you: if I have a flipflop with some
characteristic setup and hold time, and I put a delay of 1 ps on the input,
and I called this a new flipflop, how does that change any of these things?
Can make $t_{hold}$ negative. How do I add more delay? Just add more
inverters in the front. Hold time can in fact go negative. Lot of 141-style
stuff in here that you can play with.

Given that, you have to deal with the fact that you've got this propagation
time and the setup time. Cost of pipelined registers.

Critical path time, various calculations.
