Delay and Power
===============
November 27, 2012
-----------------

SDRAM recap. Gave you a handout about a week ago. In our small-outline
dual-inline memory module, we've got four chips. Each chip is 512 Mb;
overall, the whole things has in I/O D-Q width of 64; a bunch of control
signals. Address, bank address, foolishness with RAS, CAS, WE, ..., with
names that are tied back to when they did exist way back when.

All of that stuff, address pins, bank address, and everything else, cut
across those four chips: they're shared. Also write mask that goes on here
as well.

So what happens inside this thing? Inside each chip, we know that there are
address input, bank input, command input, 16-bit D-Q, and those are all
shared by four separate banks. Essentially that's all parallel, and the
only place these things come together is in these D-Q I/Os.

Separate row register, burst register, all that stuff drawn on that sheet
is replicated four times. You can give independent commands; only
difference is that you can't do it simultaneously; must be done
sequentially. Also, 200 MHz clock; all of these things are sequential,
including the clock.

So that's the picture; on the figure I drew what's inside one bank of this
thing. You've got a row address register; your address line comes in and 13
bits go into the row address register, which goes into a decoder, which
spits out 8k word lines that go across the array; inside of here the word
line activates a row of transistors that look at a storage cell, and
there's a bit line that goes up, and sitting on top of that there's a PMOS
transistor for precharge. The core of this thing is very much like the old
async DRAM chips, but now there's a bunch of digital stuff wrapped around
it.

The storage array can hold its value for some time, but you have to refresh
it every now and then (charge leakage).

That comes down to a bunch of sense amplifiers and column drivers. Amplify
that signal to get something digital, which you can latch into the row
register, or you can feed it back in. We talk about precharging on the
SDRAM, but it's really taken care of by a state machine on-chip. A lot of
terminology is now misleading.

So what's going on in here? This row register now has 256 copies of 64 bits
each on one chip, which also means in one bank; on the whole SO-DIMM, we've
got 256 by 256 bits. So you can think of this whole thing as having a bunch
of 64-bit outputs coming out of it, and that goes through a MUX which
selects those to go out a burst register.

If I've got 256 bits and I'm going to select one of them, we need eight
select bits.

You know that the chip has only 16-bit input and output; this guy has 64 kb
in his row register; you're trying to select down. A four-to-one MUX is a
lot faster than an eight-to-one MUX. This is the one that runs hyper-fast:
you get an output every rising edge of the clock.

When we put that together, the burst register is 4x16, or I can think of
this as 4x64 when I put these all together.

I latch in a row address and wait; that is propagation. etc. So again. This
is one bank inside of there, and in principle, you could have all four of
them operating in phases. Not quite as broad of an interface as you'd like,
because these pins are shared.

So if I draw my 200MHz clock as a bunch of rising edges, and I've got my
command and address inputs and my D/Q I/Os, the command interface is
synchronous with the clock (not DDR), 5 ns, if I give the command
"activate" (in the old days, this would have been the row-address strobe),
this would start the process. The decoder takes a while. Need to make sure
the row is stable.

The logic doesn't let you do that.

So I apply a row address; there's a state machine on here. There are
certain big states like IDLE, and in between them, there are several
smaller states.

In both cases, it takes some number of ticks for the state machine to do
the thing it's supposed to do.

notes: row-column delay is time between when row and column are specified;
CAS latency is time between when column is specified and when data shows
up.

Some number of states before you make it back to IDLE. Once you're back in
IDLE, you can give another activate command. That delay there is the row
precharge time (3 cycles). It turns out there's a minimum time from one
activate to a precharge command; that is the row address strobe delay (8
cycles). Finally, the row cycle latency is just the sum of the row precharge
and the row address strobe delays (11 cycles). So you see the chips given
in CAS latency, row-column delay, row precharge, and RAS (3-3-3-8 possible;
5-3-3-8 implemented on chip).

Maybe that helps explain why things are set up the way they are. If you're
interfacing with this thing, and you want to do a read on this from DDR,
one way to do that is to have registers for the four data values, which are
going to come out every 2.5 ns and have all of them share those 64-bit
lines but have their clocks be controlled by some separate thing. I can
then put those values together and stick them into a MUX that now goes into
a read-data FIFO.

If on the exam I give you specs for some real chip, I'll expect you to know
what's faster.

Last concept(s): Delay and Power. Going to go all the way back to lecture
1, when we were talking about CMOS inverters.

Time between input goes high and output goes low is $t_{pHL}$ (pull from
high to low), and the time between input goes low and output goes high is
$t_{pLH}$ (pull from low to high).

Capacitance actually now dominated not by transistors but by that of the
wire.

Truth is that transistors don't look like resistors nowadays; since we're
at velocity saturation, they look more like current sources. Reality is
that it's not actually either; it's somewhere in between. With the
definitions we've got, our times are $\tau \ln 2$; we're not going to worry
about that. So what is $RC$? $R$ can vary by orders of magnitude. But
typically they're designed so that very roughly, you get something like 1
k$\Omega$ (on the order of this; maybe tens, but not much more). $C$ is on
the order of $1 \text{ fF}/\micro \mathrm{m} (W_n + W_p)$.

So if I've got a 22nm process, and the n-channel device is ten times that
wide, and p-channel device is five times, this number might be something
like a micron, not much more; so the ballpark is that this is roughly a
femtofarad. RC therefore is about a picosecond. Light travels 300 microns
in this time. So what if my inverter is 100 micron away? Another very rough
number is about 200 fF per millimeter, which is about .2 fF per micron.

So that covers timing. How about power and energy?

We've got two components: resistors (dissipate, no storage) and capacitors
(storage, no dissipation). $\Delta E = QV = CV^2$. Power stored by the
capacitor is half of this, though. Dissipated in the form of heat by a
resistor. If you make the resistance small, this looks more like an
inductor, and we get ringing.

What frequency do we care about? Time interval between zero and one, which
is generally much less than the clock frequency. That ratio, frequency that
you go from 0 to 1 divided by the clock, is often called $\alpha$, the
activity factor. Power therefore is $\alpha CV^2 f_{clk}$.

Power is then $NCV^2 f_{clk}$ (with $N$ being the number of gates). Total
capacitance on the chip comes out to $1 \mu \mathrm{F}$, which only
switches 1V, switches 1 $\mu \mathrm{J}$, which is about a kW; depending on
the size of your chip, your heat flux may approach the surface of the
sun. $\alpha$ should be much less than 1, therefore.

