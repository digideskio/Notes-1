EE 221A: Linear System Theory
=============================
September 13, 2012
------------------

Section this Friday only, 9:30 - 110:30, Cory 299.

Today: existence and uniqueness of solutions to differential equations.

We called this a DE or ODE, and we associated with it an initial
condition. We started to talk about properties of the function $f$ as a
function of $x$ only, but we can consider thinking about this as a function
of $x$ for all t. This is a map from $\Re^n \to \Re^n$. In this class,
recall, we used the $\epsilon$-$\delta$ definition for continuity.

We also introduced the concept of piecewise continuity, which will be
important for thinking about the right-hand-side of the differential
equation.

We defined piecewise continuity as $\fn{f(t)}{\Re_+}{\Re^n}$, where $f(t)$
is said to be piecewise continuous in $t$, where the function is continuous
except at a set of well-behaved discontinuities (finitely many in any
closed and bounded, i.e. **compact**, interval).

Finally, we will define Lipschitz continuity as follows: a function
$\fn{f(\cdot, t)}{\Re^n}{\Re^n}$ is **Lipschitz continuous** in x if there
exists a piecewise continuous function of time $\fn{k(t)}{\Re_+}{\Re_+}$
such that the following inequality holds: $\mag{f(x_1) - f(x_2)} \le
k(t)\mag{x_1 - x_2}, \forall x_1, x_2 \in \Re^n, \forall t \in \Re_+$. This
inequality (condition) is called the **Lipschitz condition**.

An important thing in this inequality is that there has to be one function
$k(t)$, and it has to be piecewise continuous. That is, there exists such a
function that is not allowed to go to infinity in compact time
intervals.

It's an interesting condition, and if we look at this and compare the
Lipschitz continuity definition to the general continuity definition, we
can easily show that if the function is LC (Lipschitz continuous), then
it's C (continuous), since LC is a stricter condition than C. That
implication is fairly straightforward to show, but the inverse relationship
is not necessarily true (i.e. continuity does not necessarily imply
Lipschitz continuity).

Aside: think about this condition and what it takes to show that a function
is Lipschitz continuous. Need to come up with a candidate $k(t)$ (often
called the Lipschitz function or constant, if it's constant). Often the
hardest part: trying to extract from $f$ what a possible $k$ is.

But there's a useful possible candidate for $k(t)$, given a particular
function $f$. Let's forget about time for a second and consider a function
just of $x$. If the **Jacobian** $Df$ (often you also use $\pderiv{f}{x}$),
which is an $n \times n$ matrix (where $(Df)^j_i = \pderiv{f_j}{x_i}$. If
the Jacobian $Df$ exists, then its norm provides a candidate Lipschitz
function $k(t)$.

A norm of the Jacobian of $f$, if independent of $x$, tells you that the
function is Lipschitz. If the norm always seems to depend on $x$, you can
still say something about the Lipschitz properties of the function: you can
call it locally Lipschitz by bounding the value of $x$ in some region.

Sketch of proof: generalization of mean value theorem (easy to sketch in
$\Re^1$). Mean value theorem states that there exists a point such that the
instantaneous slope is the same as the average slope (assuming that the
function is differentiable). If we want to generalize it to more
dimensions, we say $f(x_1) - f(x_2) = Df(\lambda x_1 + (1 - \lambda)
x_2)(x_1 - x_2)$ (where $0 < \lambda < 1$). All we've required is the
existence of $Df$.

Now we can just take norms (and this is what's interesting now) and use
some of the results we have from norms. This provides a very useful
construction for a candidate for $k$ (might not provide a great bound), but
it's the second thing to try if you can't immediately extract out a
function $k(t)$.

Something not in the notes, but useful. Let's go back to where we started,
the differential equation with initial condition, and state the main
theorem.

Fundamental Theorem of DEs / the Existence and Uniqueness theorem of (O)DEs
---------------------------------------------------------------------------
suppose we have a differential equation with an initial condition. Assume
that $f(x)$ is piecewise continuous in $t$ and Lipschitz continuous in
$x$. With that information, we have that there exists a unique function of
time which maps $\Re_+ \to \Re^n$, which is differentiable ($C^1$) *almost*
everywhere (derivative exists at all points at which $f$ is continuous),
and it satisfies the initial condition and differential equation. This
derivative exists at all points $t \in [t_1, t_2] - D$, where
$D$ is the set of points where $f$ is discontinuous in $t$.

We are going to be interested in studying differential equations where we
know these conditions hold. We're also going to prove the theorem. It's a
nice thing to do (a little in depth) because it demonstrates some proof
techniques (as well as giving you an idea of why the theorem works).

LC condition
------------

The norm of the Jacobian of the example is bounded for bounded $x$. That
is, we can choose a local region in $\Re$ for which our $Df$ is bounded to
be less than some constant. That gives us a candidate Lipschitz constant
for that local region. We say then that $f(x)$ is (at least) **locally
Lipschitz continuous** (usually we just say this without specifying a
region, since you can usually find a bound given any region). Further, it
is trivially piecewise continuous in time (since it doesn't depend on
time).

Note: if the Lipschitz condition holds only locally, it may be that the
solution is only defined over a certain range of time.

We didn't show this, but in this example, the Lipschitz condition does not
hold globally.

Local Fundamental theorem of DEs
--------------------------------

Now assume that $f(x)$ is piecewise continuous in $t$ and Lipschitz
continuous in $x$ (for all $x \in G \in \Re^n$). We now have that there
exists a unique function of time and an interval $[t_0,t_1]$ (such that
$t_0 \in G, t_1 \in G$) which maps $\Re_+ \to \Re^n$, which is
differentiable ($C^1$) *almost* everywhere (derivative exists at all points
at which $f$ is continuous), and it satisfies the initial condition and
differential equation. As before, This derivative exists at all points $t
\in [t_1, t_2] - D$, where $D$ is the set of points where $f$ is
discontinuous in $t$. If it is global, we can make the interval as large as
desired.

Proof
-----
There are two pieces: the proof of existence and the proof of
uniqueness. Today will likely just be existence.

Existence
---------
Roadmap: construct an infinite sequence of continuous functions defined
(recursively) as follows $x_{m+1}(t) = x_0 + \int_{t_0}^t f(x_m(\tau),
\tau) d\tau$. First, show that this sequence converges to a continuous
function $\fn{\Phi(\cdot)}{\Re_+}{\Re^n}$ which solves the DE/IC pair.

Would like to be able to prove the first thing here: I've constructed a
sequence, and I want to show that the limit of this sequence is a solution
to the differential equation.

The tool that I'm going to use is a property called Cauchy, and then I'm
going to invoke the result that if I have a complete space, any Cauchy
sequence on the space converges to something in the space. Gives me the
basis of the existence of the thing that this converges to.

Goal: (1) to show that this sequence is a Cauchy sequence in a
complete normed vector space, which means the sequence converges to
something in the space, and (2) to show that the limit of this sequence
satisfies the DE/IC pair.

A **Cauchy sequence** (on a normed vector space) is such that there exists
some point in the sequence (some finite index $m$) such that if you look at
any point beyond that index, the distance between the later points can be
made smaller than some arbitrarily small $\epsilon > 0$. In other words: if
we drop a finite number of elements from the start of the sequence, the
distance between any remaining elements can be made arbitrarily small.

We define a **Banach space** (equivalently, a **complete normed vector
space**) is one in which all Cauchy sequences converge. Implicitly in that,
it means to something in the space itself.

Just an aside, a **Hilbert space** is a **complete inner product
space**. If you have an inner product space, and you define the norm in
that inner product space induced by that inner product, if all Cauchy
sequences of that space converge (to a limit in the space) with this norm,
then it is a Hilbert space.

Think about a Cauchy sequence on a space that converges to something not
necessarily in the space. Example: any continued fraction.

To show (1), we'll show that this sequence $\{x_m\}$ that we constructed is
a Cauchy sequence in a Banach space. Interestingly, it matters what norm
you choose.
