Controllability and Observability: Grammians and tools
======================================================
November 13, 2012
----------------

Controllability of $[A, B]$
--------------------------

$s(t_1, t_0, x_0, u_{[t_0, t_1]}) = \Phi(t_1, t_0) x_0 + \int_{t_0}^{t_1}
\Phi(t_1,\tau)B(\tau)u(\tau)d\tau$

We refer to the term with the integral as $\mathcal(L)_c(u)$ (**L**inear
**c**ontroller map). Recall that we showed that controllability of $[A,B]$
on $[t_0, t_1]$ is equivalent to surjectivity of $\mathcal{L}_c$.

Grammians: matrix tests for controllability and observability for
time-varying systems, and end up being something quite nice in the LTI
case.

Recall: a system is said to be controllable if for any pair of states,
there exists an input that takes you from the initial state to the terminal
state over this time interval. We further discussed that this was
equivalent to saying that we could reach any final state from 0, which was
further equivalent to saying that we could reach 0 from any initial
state. (reachability from the origin, steering to the origin)

Let us pair this, now, with

Observability
-------------

You have your model, final state, and some defined time interval, and from
that information, you can uniquely determine the initial state of the
system. For now we'll assume we know the input, but that turns out to be
extraneous information.

Response map is the readout map composed with state transition function: in
particular, it has memory.

Given the output and the input, observability relates to uniquely
determining the initial state. Just as we isolated the term that depended
on input in the controllability case, in observability, we isolate the
dependence on the initial state.

We've turned injectivity of $\rho$ to injectivity of the linear operator
$\fn{\mathcal{L}_o}{\Sigma}{Y} \defequals C(t_1)\Phi(t_1, t_0)x_0$
(**L**inear **o**bservability map).

Theorem: complete observability of the system $A, C$ on the interval
$[t_0, t_1]$ is equivalent to saying that $\mathcal{N}(\mathcal{L}_o) =
{\theta_n}$ (injectivity of the observability map; saying that nullspace is
trivial)

Controllability and Observability grammians; named after the same Gram of
Gram-Schmidt. Recall work in adjoints: we'll turn these tests into matrix
tests through our knowledge of adjoint maps.

Recall: adjoint of linear maps. Take two inner product spaces and a map
that goes from one space to the other. The map's adjoint is defined in
terms of the inner product.

We can show that the adjoint of the linear controller map is simply
$B^*(\cdot)\Phi^(t_1, \cdot)*$: just consider the inner product; bring
$v^T$ under the integral.

Given $\fn{\mathcal{A}}{\mathcal{U}{V}}$, we have the following
propositions:

# $V = R(A) \perp\over\oplus N(A^*)$

# $U = R(A^*) \perp\over\oplus N(A)$

What we'd want to show is one pair; you'd prove this by showing that the
nullspace of $A^*$ is perpendicular to the range of $A$.

You'll often see this as bubble diagrams: the space $U$ is often drawn as
two bubbles that intersect only at the zero vector.

More important propositions:

# $N(AA^*) = N(A^*)$

# $R(AA^*) = R(A)$

# $N(A^*A) = N(A)$

# $R(A^*A) = R(A^*)$

These are very important. Quick sketch of proof of (1): show that the norm
induced by the adjoint map of anything in $N(AA^*)$ is the zero vector;
this is adequate.

Sketch of proof of (2): use decomposition from above propositions ($u_1 \in
R(A^*), u_2 \in N(A)$; apply $A$ to this.

We've deviated a little. Started with tests for controllability and
observability; did adjoints, showed decomposition of domain and codomain
spaces when mapping through $A$ and its adjoint, we showed how to break
down these spaces.

We can now relate these to our observability and controllability tests.

Controllability
---------------

$\fn{\mathcal{L}_c}{\mathcal{U}_{[t_0, t_1]}}{\Re^n} = \int_{t_0}^{t_1}
\Phi(t_1, \tau)B(\tau)u(\tau)$. Recall that we just computed that
$\mathcal{L}_c^*(x) = B^*(\cdot)\Phi(t_1, \cdot)x$. Complete
controllability on this interval, using a proposition from above, is
equivalent to the following: $R(\mathcal{L}_v) = \Re^n =
R(\mathcal{L}_c\mathcal{L}_c^*)$. This is often easier to
compute. Composition of $\mathcal{L}_c$ with $\mathcal{L}_c^*$ yields
$\int_{t_0}^{t_1}\Phi(t_1, \tau) B(\tau)B^*(\tau)\Phi^*(t_1, \tau) d\tau$,
which is an $n\times n$ matrix. The system is completely controllable on
this interval iff $W_c$ (the **controllability grammian**) has full rank.

If you look at the integrand, this matrix is a (symmetric) positive
semidefinite matrix (just write it in terms of the norm). If completely
controllable, it is positive definite.

exercise. hint: look at quadratic form, e.g. $x^* W_c x$, and show, using
that quadratic form for any $x$, that it's positive semi-definite. Our
controllability test is that $\text{rank } W_c = n$.

Observability
-------------

Recall this involved looking at the nullspace of the map. $\mathcal{L}_o^*
\mathcal{L}_o y(\cdot) = \int_{t_0}^{t_1} \Phi^*(\tau, t_0) C^*(\tau)
C(\tau) \Phi(\tau, t_0) y(\tau) d\tau$. Complete observability claims that
this composition of maps has full rank. This is called $W_o$, the
observability grammian. Turned some fairly abstract tests into something
that's more concrete; matrix that involves computing state transition
matrix. Main theme is to get at simple tests for the time-invariant
case. Todo: show how these grammians simplify to very simple grammians for
the time-invariant case.

Last five minutes: talk about the controller and observability maps, what
they mean in terms of grammians.

Kalman filters; some thoughts about observability
-------------------------------------------------

Kalman filter: the way we tend to reconstruct state from measurements given
our understanding of the system.

We started today by talking about the nullspace of the observability map
being trivial. So how do we solve for $x_0$? Use the left-inverse, if this
is completely observable. Let's take that equation and pre-multiply both
sides by $\mathcal{L}_o^*$. We know that this product ($\mathcal{L}_o^*
\mathcal{L}_o$) is bijective, so we can invert it. Not actually done in
Kalman filters; keep a running estimate.
