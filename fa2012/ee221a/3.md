EE 221A: Linear System Theory
=============================
August 30, 2012
---------------

From last time
--------------
Subspaces, bases, linear dependence/independence, linearity. One of the
main things we're going to do is look at properties of linear functions and
representation as multiplication by matrices.

Example (of a vector space)
---------------------------
$\ell_2 = \{v = \{v_1, v_2, ...\} \st \sum_{i=1}^\infty \abs{v_i}^2 <
\infty, v_i \in \Re \}$

Vector addition and scalar multiplication? ("pointwise" addition,
multiplication by reals)

What is a vector subspace?
--------------------------

Consider vector space $(V, \mathbb{F})$. Consider a subset W of V combined
with the same field. $(W, \mathbb{F})$ is a subspace of $(V, \mathbb{F})$
if it is closed under vector addition and scalar multiplication (formally,
this must be a vector space in its own right, but these are the only
vector space properties that we need to check).

Consider vectors from $\Re^n$. A plane (in $\Re^3$) is a subspace of
$\Re^3$ if it contains the origin.

Aside: for $x \in V$, **span**$(x) = \alpha x, \alpha \in \mathbb{F}$.

Linear dependence, linear independence.
---------------------------------------

Consider a set of $p$ vectors $\{v_1, v_2, ..., v_p\}, v_i \in V$. This set
of vectors is said to be a **linear independent set** iff no nontrivial
homogeneous equation exists, i.e. $\sum_i \alpha_i v_i = 0 \implies \forall
i, \alpha_i = 0$. This is equivalent to saying that no one vector can be
written as a linear combination of the others.

Otherwise, the set is said to be **linearly dependent**.

Bases
-----

Recall: a set of vectors $W$ is said to span a space $(V, \mathbb{F})$ if
any vector in the space can be written as a **linear combination** of
vectors in the set, i.e. $\forall v \in V, \exists \set{(\alpha_i,
w_i)}{v = \sum \alpha_i w_i}$ for $w_i \in W, \alpha_i \in \mathbb{F}$.

W is a **basis** iff it is also linearly independent.

Coordinates
-----------

Given a basis $B$ of a space $(V, \mathbb{F})$, there is a unique
representation (trivial proof) of every $v \in V$ as a linear combination
of elements of $B$. We define our **coordinates** to be the coefficients
that appear in this unique representation. A visual representation is the
**coordinate vector**, which defines

$$\alpha = \begin{bmatrix}\alpha_i \\ \vdots \\ \alpha_n \end{bmatrix}$$

Basis is not uniquely defined, but what is constant is the number of
elements in the basis. This number is the **dimension** (rank) of the
space. Another notion is that a basis generates the corresponding space,
since once you have a basis, you can acquire any element in the space.

Linearity
---------
A function $\fn{f}{(V, \mathbb{F})}{(W, \mathbb{F})}$ (note that these
spaces are defined over the same field!) is **linear** iff $f(\alpha_1 v_1 +
\alpha_2 v_2) = \alpha_1 f(v_1) + \alpha_2 f(v_2)$.

This property is known as **superposition**, which is an amazing property,
because if you know what this function does to the basis elements of a
vector space, then you know what it does to *any* element in the space.

An interesting corollary is that a linear map will *always* map the zero
vector to itself.

Definitions associated with linear maps
---------------------------------------

Suppose we have a linear map $\fn{\mathcal{A}}{U}{V}$. The **range
(image)** of $\mathcal{A}$ is defined to be $R(\mathcal{A}) = \set{v}{v =
A(u), u \in U} \subset V$. The **nullspace (kernel)** of $\mathcal{A}$ is
defined to be $N(\mathcal{A}) = \set{u}{\mathcal{A}(u) = 0} \subset U$. Also
trivial (from definition of linearity) to prove that these are subspaces.

We have a couple of very important properties now that we've defined range
and nullspace.

Properties of linear maps $\fn{\mathcal{A}}{U}{V}$
-------------------------

$$(b \in V) \implies (\mathcal{A}(u) = b \iff b \in R(\mathcal{A}))$$

$$(b \in R(\mathcal{A})) \iff (\exists!\ u\ \st \mathcal{A}(u) = b \iff
[N(\mathcal{A}) = 0])$$

(if the nullspace only contains the zero vector, we say it is **trivial**)

$$\mathcal{A}(x_0) = \mathcal{A}(x_1) \iff x - x_0 \in N(\mathcal{A})$$
