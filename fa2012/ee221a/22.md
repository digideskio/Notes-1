Controllability and Observability
=================================
November 8, 2012
----------------

Difference between dynamical system and its representation. Instantiating
it with the representation is simply our model of the system; the system
itself is just the five-tuple. Same system with different representations;
notion of a minimal representation. Controllability and observability are
properties of a representation.

The computational tests for controllability and observability -- these
grammians -- are dependent on the system representations.

We can define it more basically with the properties of the state transition
function and the readout map (rather, recall that the composition of the
two yields the response function).

note: cc = completely controllable, co = completely observable.

We discussed what it meant for an input to steer the system, and then we
defined controllability to be surjectivity of the state transition
function. In other words, a dynamic system $D$ is controllable on
$\bracks{t_0, T_1}$ if the response map (from inputs to states, given some
initial conditions) is surjective.

We'll now define observability as follows: $D$ is said to be observable on
$\bracks{t_0, t_1}$ if for all valid input functions and all valid output
functions, the initial state $x_0$ at $t_0$ is uniquely determined. In
other words, the response map $\rho(t_1, t_0, \cdot, u)$ is injective.

What happens with controllability and observability under feedback? We're
going to talk about feedback and one feed-forward topology. What can we say
about the composite system? Is controllability / observability preserved
with feedback? We're going to look at two kinds of feedback: state feedback
and output feedback.

Memoryless feedback
-------------------

No memory; static. Recall that the solution to LQR was just linear state
feedback. That's memoryless: takes the state and multiplies by a constant
gain matrix.

State feedback takes states and gives us inputs; output feedback takes
outputs and gives us inputs.

Suppose you have a dynamical system $D$. We can actually measure the state
and feed it back through this function $F_s$ to construct a new input.

Negative state feedback -- subtract this from our input. Initial input is
the **auxiliary input**.

The output feedback case is typically more popular because we don't usually
have the state to measure. We can no longer measure the state, but we can
take the output.

With these feedback forms, we're going to make the **well-posedness
assumption**: for all auxiliary inputs $v$ and all initial states and
times, when you look at the algebraic relationships of those forms, there
exists unique trajectories $x(t), y(t)$ over that time interval.

If you don't have well-posedness, you can come up with problems: consider
$A=B=C=0, D=1, u = v+y$. The only $v$ that works is 0.

If we have that the systems are well-posed, we can make some nice
observations about the observability of the feedback forms.

The first theorem states the following: suppose you have a well-posed
system. $D$ is controllable on the interval iff $D_s$ is controllable on
the same interval, and iff $D_o$ is controllable on the same interval.

Namely, controllability is preserved under static state feedback.

Formally rests on the fact that $F_s, F_o$ are known maps. We have all
information to be able to compute one input from the other uniquely (by
well-posedness assumption).

Observability
-------------

Still considering memoryless output feedback, but now we're also going to
consider input feed-forward.

We have another system: D is observable on $\bracks{t_0, t_1}$ iff $D_o$ is
observable and iff $D_f$ is observable.

$D$ is observable on interval given all valid inputs and outputs over
the time interval if there exists a unique initial condition.

We've talked about preservation of controllability over state and output
feedback; we've talked about preservation of observability of output
feedback and feedforward. But the case we've missed is state feedback. Is
observability preserved by state feedback? The answer, in general, is
no. We can explain this in a couple of ways.

Observability is not necessarily preserved over state feedback -- consider
nullspace of $F_f$.

Dynamic feedback. More assumptions that have to be made. Up to now, we've
been assuming that all of these feedback / feedforward functions are
memoryless. What if they actually have dynamics associated to them? A lot
of control design involves using dynamic controllers.

In general these properties we've talked about (preservation of
controllability / observability) hold for the memoryless case. If we now
consider that the feedback and feedforward systems themselves are dynamical
systems (and have memory), we have to be careful in what we mean by
controllability and observability of the resulting system.

The input space of a state feedback function is the space of state
trajectories of $D$, and the output space is the input space of $D$.

In order to talk about preservation of controllability and observability,
we must now about the controllability and observability of the feedback
system (i.e. the "loop").

We're going to actually approach that later. For now, skip over
preservation of controllability and observability under dynamic (state and
output) feedback until later. We'll discuss different topologies under
which these are preserved. We'll return to it under the pretext of
controllability and observability of linear systems.

Grammians
---------

Given a system representation, how do we construct tests for
controllability and observability? We have a test for the linear
time-varying case, which is in general hard to compute, and tests for the
linear time-invariant case, which are easier. In both cases, they're both
matrix-rank conditions.

Controllability Grammians
-------------------------

Let us look at our linear system representation and focus on the
time-varying case. When we talk about controllability of a linear system,
we care about controllability of $(A, B)$ -- we know that controllability
on $\bracks{t_0, t_1}$ is the same as surjectivity of the state transition
function, which is defined only in terms of $A, B$: recall that $s(t_1,
t_0, x_0, u_{[t_0,t_1]}(\cdot)) = \Phi(t_1,t_0)x_0 + \int_{t_0}^{t_1}
\Phi(t, \tau)B(\tau) u(\tau) d\tau$. Let us refer to the integral as
$\mathcal{L}_c(u)$, which maps input functions to states. Now we can
characterize controllability in the following manner: we say that $(A,B)$
(or generally $R$) is completely controllable on $[t_0, t_1]$ iff
$R(\mathcal{L}_c) = \Re^n$, which is equivalent to saying $\forall x_0 \in
\Re^n \exists u_{[t_0,t_1]}$ that steers $(x_0, t_0)$ to $(\theta_m, t_1)$
(steering to origin), which is further equivalent to saying that you can
steer $\theta_m$ to any state (reaching from origin).

What is initially unintuitive is that saying either of the two later
statements is equivalent to saying the first statement. Notion of equating
this to any vector in $\Re^n$. Because the first piece of the state
transition function does not depend on $u$, it all boils down to
surjectivity to $\mathcal{L}_c(u)$ (since this is the only part that
depends on $u$). Thus surjectivity of $s(u)$ is equivalent to surjectivity
of $\mathcal{L}_c(u)$.
