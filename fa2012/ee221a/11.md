Linear time-Invariant systems
=============================
September 27, 2012
------------------
Last time, we talked about the time-varying differential equation, and we
expressed $R(\cdot) = \bracks{A(\cdot), B(\cdot), C(\cdot),
D(\cdot)}$. Used state transition matrix to show that the solution was
given by $x(t) = \Phi(t, t_0) x_0 + \int_{t_0}^t B(\tau) u(\tau)
d\tau$. Integral part is the state transition matrix, and we haven't
talked about how we would compute this matrix. In general, computing the
state transition matrix is hard. But there's one important class where
computing that class becomes much simpler than usual. That is where the
system does not depend on time.

Linear time-invariant case: $\dot{x} = Ax + Bu, y = Cx + Du, x(t_0) =
x_0$. Does not matter at what time we start. Typically, WLOG, we use $t_0 =
0$ (we can't do this in the time-varying case).

Aside: Jacobian linearization
-----------------------------
In practice, generally the case that someone
doesn't present you with a model that looks like this. Usually, you derive
this (usually nonlinear) model through physics and whatnot. What can I do
to come up with a linear representation of that system? What is typically
done is an approximation technique called Jacobian linearization.

So suppose someone gives you a nonlinear system and an output equation,
and you want to come up with some linear representation of the system.

Two points of view: we could look at the system, and suppose we applied a
particular input to the system and solve the differential equation
($u^0(t) \mapsto x^0(t)$, the **nominal input** and **nominal
solution**). That would result in a solution (**state trajectory**, in
general). Now suppose that we for some reason want to perturb that input
($u^0(t) + \delta u(t)$, the **perturbed input**). Suppose in general
that $\delta u$ is a small perturbation. What this results in is a new
state trajectory, that we'll define as $x^0(t) + \delta x(t)$, the
**perturbed solution**.

Now we can derive from that what we call the Jacobian linearization. That
tells us that if we apply the input, the solution will be $x^0 =
f(x^0, u^0, t)$, and I also have that $x^0(t_0) = x_0$.

$\dot{x}^0 + \dot{\delta}x = f(x^0 + \delta x, u^0 + \delta u, t)$, where
$(x^0 + \delta x)(t_0) = x_0 + \delta x_0$. Now I'm going to look at these
two and perform a Taylor expansion about the nominal input and
solution. Thus $f(x^0 + \delta x, u^0 + \delta u, t) = f(x^0, u^0, t) +
\pderiv{}{x} f(x, u, t)\vert_{(x^0, u^0)}\delta x +
\pderiv{}{u}f(x,u,t)\vert_{(x^0, u^0)} \delta u + \text{higher order
terms}$ (recall that we also called $\pderiv{}{x}$ $D_1$, i.e. the
derivative with respect to the first argument).

What I've done is expanded the right hand side of the differential
equation. Thus $\delta x = \pderiv{}{x} f(x, u, t)\vert_{(x^0, u^0)} \delta
x + \pderiv{}{u} f(...)\vert_{(x^0, y^0)}\delta u + ...$. If $\delta u,
\delta x$ small, then we can assume that they are approximately zero, which
gives us an approximate first-order linear differential equation. This
gives us a linear time-varying approximation of the dynamics of this
perturbation vector, in response to a perturbation input. That's what the
Jacobian linearization gives you: the perturbation away from the nominal
(we linearized about a bias point).

Consider A(t) to be the Jacobian matrix with respect to x, and B(t) to be
the Jacobian matrix with respect to u. Remember that this is an
approximation, and if your system is really nonlinear, and you perturb the
system a lot (stray too far from the bias point), then this linearization
may cease to hold.

Linear time-invariant systems
-----------------------------
Motivated by the fact that we have a solution to the time-varying equation,
it depends on the state transition matrix, which right now is an abstract
thing which we don't have a way of solving. Let's go to a more specific
class of systems: that where $A, B, C, D$ do not depend on time. We know
that this system is linear (we don't know yet that it is time-invariant; we
have to find the response function and show that it satisfies the
definition of a time-invariant system), so this still requires proof.

Since these don't depend on time, we can use some familiar tools
(e.g. Laplace transforms) and remember what taking the Laplace transform of
a derivative is. Denote $\hat{x}(s)$ to be the Laplace transform of
$x(t)$. The Laplace transform is therefore $s\hat{x}(s) - x_0 = A\hat{x}(s)
+ B\hat{u}(s)$; $s\hat{y}(s) - y_0 = C\hat{x}(s) + D\hat{u}(s)$. The first
equation becomes $(sI - A)\hat{x}(s) = x_0 + B\hat{u}(s)$, and we'll leave
the second equation alone.

Let's first consider $\hat{x} = Ax$, $x(0) = x_0$. I could have done the
same thing, except my right hand side doesn't depend on B: $(sI -
A)\hat{x}(s) = x_0$. Let's leave that for a second and come back to it, and
make the following claim: the state transition matrix for $\hat{x} = Ax,
x(t_0) = x_0$ is $\Phi(t,t_0) = e^{A(t-t_0)}$, which is called the **matrix
exponential**, defined as $e^{A(t-t_0)} = I + A(t-t_0) + \frac{A^2(t-t_0)^2}{2!}
+ ...$ (Taylor expansion of the exponential function).

We just need to show that the state transition matrix, using definitions we
had last day, is indeed the state transition matrix for that system. We
could go back to the definition of the state transition matrix for the
system, or we could go back to the state transition function for the vector
differential equation.

From last time, we know that the solution to $\dot{x}A(t)x, x(t_0) = x_0$
is given by $x(t) = \Phi(t, t_0)x_0$; here, we are claiming then that $x(t)
= e^{A(t - t_0)} x_0$, where $x(t)$ is the solution to $\dot{x} = Ax$ with
initial condition $x_0$.

First show that it satisfies the vector differential equation: $\dot{x} =
\pderiv{}{t}\exp\parens{A(t-t_0)} x_0 = (0 + A + A^2(t - t_0 + ...)x_0 =
A(I + A(t-t_0) + \frac{A^2}{2}(t-t_0)^2 + ...) x_0 = Ae^{At} x_0 = Ax(t)$,
so it satisfies the differential equation. Checking the initial condition,
we get $e^{A \cdot 0}x_0 = I x_0 = x_0$. We've proven that this represents
the solution to this time-invariant differential equation. By the existence
and uniqueness theorem, this is the same solution.

Through this proof, we've shown a couple of things: the derivative of the
matrix exponential, and we evaluated it at $t-t_0=0$. So now let's go back
and reconsider its infinite series representation and classify some of its
other properties.

Properties of the matrix exponential
------------------------------------

* $e^0 = I$
* $e^{A(t+s)} = e^{At}e^{As}$
* $e^{(A+B)t} = e^{At}e^{Bt}$ iff $\comm{A}{B} = 0$.
* $\parens{e^{At}}^{-1} = e^{-At}$, and these properties hold in general if
  you're looking at $t$ or $t - t_0$.
* $\deriv{e^{At}}{t} = Ae^{At} = e^{At}A$ (i.e. $\comm{e^At}{A} = 0$)
* Suppose $X(t) \in \Re^{n \times n}$, $\dot{X} = AX, X(0) = I$, then the
  solution of this matrix differential equation and initial condition pair
  is given by $X(t) = e^{At}$. Proof in the notes; very similar to what we
  just did (more general proof, that the state transition matrix is just
  given by the matrix exponential).

Calculating $e^{At}$, given $A$
-------------------------------

What this is now useful for is making more concrete this state transition
concept. Still a little abstract, since we're still considering the
exponential of a matrix.

The first point is that using the infinite series representation to compute
$e^{At}$ is in general hard.

Would be doable if you knew $A$ were nilpotent ($A^k = 0$ for some $k \in
\mathbb{Z}$), but it's not always feasible. Would not be feasible if $k$
large.

The way one usually computes the state transition matrix $e^{At}$ is as
follows:

Recall: $\dot{X}(t) = AX(t)$, with $X(0) = I$. We know from what we've done
before (property 6) that we can easily prove $X(t) = e^{At}$. We also know
that $(sI - A)\hat{X}(s) = I$, so $\hat{X}(s) = (sI - A)^{-1}$. That tells
me that $e^{At} = \mathcal{L}^{-1}\parens{(sI - A)^{-1}}$. That gives us a
way of computing $e^{At}$, assuming we have a way to compute a matrix's
inverse and an inverse Laplace transform. This is what people usually do,
and most algorithms approach the problem this way. Generally hard to
compute the inverse and the inverse Laplace transform.

Requires proof regarding why $sI - A$ always has an inverse given by
$e^{-At}$.

Clive Moller started LINPACK (Linear algebra package; engine behind
MATLAB). Famous in computational linear algebra. Paper: 19 dubious ways to
compute the matrix exponential. Actually a hard problem in
general. Factoring of $n$-degree polynomials.

If we were to consider our simple nilpotent case, we'll compute $sI - A =
\begin{bmatrix}s & -1 \\ 0 & s\end{bmatrix}$. We can immediately write down
its inverse as $\begin{bmatrix}\frac{1}{s} & \frac{1}{s^2} \\ 0 &
\frac{1}{s}\end{bmatrix}$. Inverse Laplace transform takes no work; it's
simply $\begin{bmatrix}1 & t \\ 0 & 1\end{bmatrix}$.

In the next lecture (and next series of lectures) we will be talking about
the Jordan form of a matrix. We have a way to compute $e^{At}$. We'll write
$A = TJT^{-1}$. In its simplest case, it's diagonal. Either way, all of the
work is in exponentiating $J$. You still end up doing something that's the
inverse Laplace transform of $sI - J$.

We've shown that for a linear TI system, $\dot{x} = Ax + Bu$; $y = Cx + Du$
($x(0) = x_0$). $x(t) = e^{At}x_0 + \int_0^t e^{A(t-\tau)} Bu(\tau)
d\tau$. We proved it last time, but you can check this satisfies the
differential equation and initial condition.

From that, you can compute the response function and show that it's
time-invariant. Let's conclude today's class with a planar inverted
pendulum. Let's call the angle of rotation away from the vertical $\theta$,
mass $m$, length $\ell$, and torque $\tau$. Equations of motion: $m\ell^2
\ddot{\theta} - mg\ell \sin \theta = \tau$. Perform Jacobian
linearization; we'll define $\theta = 0$ at $\pi/2$, and we're linearizing
about the trivial trajectory that the pendulum is straight up. Therefore
$\delta \theta = \theta \implies m\ell^2 \ddot{\theta} + mg\ell\theta
= \tau$, where $u = \frac{\tau}{m\ell^2}$, and $\Omega^2 = \frac{g}{\ell}$,
$\dot{x}_1 = x_2$, and $\dot{x}_2 = \Omega^2 x_1 + u$.

$y = \theta - x_1, \dot{x}_1 = x_2, \dot{x}_2 = \Omega^2 x_1 + u, y =
x_1$. Stabilization of system via feedback by considering poles of Laplace
transform, etc. $\frac{\hat{y}}{\hat{u}} = \frac{1}{s^2 - \Omega^2} =
G(s)$ (the plant).

In general, not a good idea: canceling unstable pole, and then using
feedback. In the notes, this is some controller $K(s)$. If we look at the
open-loop transfer function ($K(s)G(s) = \frac{1}{s(s+\Omega)}$), $u =
\frac{s-\Omega}{s}\bar{u}$, so $\dot{u} = \dot{\bar{u}} - \Omega\bar{u}$
(assume zero initial conditions on $u, \bar{u}$). If we define a third
state variable now, $x_3 = u - \bar{u}$, then that tells us that $\dot{x}_3
= \Omega \bar{u}$. Here, I have $A = \begin{bmatrix} 0 & 1 & 0 \\ \Omega^2
& 0 & -1 \\ 0 & 0 & 0 \end{bmatrix}$, $B = \begin{bmatrix}0 \\ 1 \\
\Omega\end{bmatrix}$, $C = \begin{bmatrix}1 & 0 & 0\end{bmatrix}$, $D =
0$. Out of time today, but we'll solve at the beginning of Tuesday's class.

Solve for $x(t) = \begin{bmatrix}x_1, x_2, x_3\end{bmatrix}$. We have a few
approaches:

* Using $A,B,C,D$: compute the following: $y(t) = Ce^{At} x_0 + C\int_0^t
  e^{A(t - \tau)}Bu(\tau) d\tau$. In doing that, we'll need to compute
  $e^{At}$, and then we have this expression for general $u$: suppose you
  supply a step input.
* Suppose $\bar{u} = -y = -Cx$. Therefore $\dot{x} = Ax + B(-Cx) = (A -
  BC)x$. We have a new $A_{CL} = A - BC$, and we can exponentiate this
  instead.

Foreshadows later, when we think about control. Introduces this standard
notion of feedback for stabilizing systems. Using newfound knowledge of
state transition matrix for TI systems (how to compute it), see how to
compute. See what MATLAB is doing.
