Internal stability, Lyapunov condition for LTI systems, Controllability / Observability
=====================
November 6, 2012
----------------

LTI case: $\dot{x} = Ax$. Asymptotic / exponential stability iff all
eigenvalues of A in $C_-^o$. Stability iff all eigenvalues in $C_-$ and
each eigenvalue on $j\omega$ axis has J-block of size 1.

Connections between internal stability and BIBO stability
---------------------------------------------------------

Go back to general linear time-varying case. If we have the result that
equilibrium at 0 (WLOG) is equal to 0 (zero-input case) is exponentially
stable, then assuming (which we do) that $B,C,D$ are boudned matrices, then
the system is BIBO stable.

We just need to show, now, that given that this is exponentially stable,
the condition (with weighting patterns and all) for BIBO stability holds.

(show, as an exercise, that given those bounds, and given our knowledge
that this is an exponentially stable system and we can develop a bound on
the norm, that this is BIBO).

What if $\dot{x} A$ is just asymptotically stable? Do we have BIBO
stability? Something to think about.

We know from our examples that a system may be BIBO stable but not
internally stable (notion of modes being blocked by $B$ or not exposed by
$C$) due to the possibility of what we call **hidden modes**,
i.e. eigenvalues of $A$ may be not accessible through the input or
invisible at the output.

So when can you relate BIBO stability to internal stability? Foreshadowing
of what we'll start in a minute.

If we have an LTI system, we say that if the (A,B) pair is completely
controllable, and the (A,C) pair is completely observable, then we call the
system (A,B,C) minimal. If this is the case, then it's true that BIBO
stability is equivalent to internal exponential stability.

For linear time-variant systems, I'll make one remark. Often tempting to
look at eigenvalues of A(t). In general there is no connection between the
spectrum of A(t) ($\sigma(A(t))$) and the stability of the system.

There are two cases in which the eigenvalues tell us something about the
stability:

* A is symmetric (or more generally, $\comm{A^\dag A}{AA^\dag} = 0$): A can
  be decomposed into an orthonormal basis of eigenvectors corresponding to
  real eigenvalues. If $\sigma(A(t)) \le -\mu$ ($\mu > 0$), then we have
  that equilibrium at 0 is exponentially stable.
  
  * Proof: Consider $V(x) = x^Tx$. Its time derivative (actually a special
    kind of derivative) is $\dot{x}^Tx + x^T\dot{x} = 2x^TAx$. Rewrite $A =
    T^{-1} \Lambda T$, and we have $x^TAx = x^{-1}T \Lambda T x$ (we have
    that $T^{-1} = T^T$). Our initial assumption gives us an upper bound on
    the product $x^T A x$, which tells us that $\dot{V} \le -2\mu V$. We can
    integrate this inequality and come up with the following equation:
    $V(x(t)) \le V(x(0))\exp(-2\mu t)$. Note that $V$ is a norm of $x$, so
    using this norm, we have that $\mag{x(t)}^2 = \mag{x(0)}^2\exp(-2\mu t)$,
    so $\mag{x(t)} = \mag{x(0)}\exp(-\mu t)$.
	
  * The reason why this proof is interesting is that it invokes a technique
    common to control theory: we bring in this function and use the
    derivative to establish the stability of the system. This is a special
    case of what we call a Lyapunov function. Lyapunov theory is the most
    popular tool for assessing stability.

* $Re(A(t)) < -\lambda and \mag{A(t)} \le \epsilon$, with $\epsilon$ small
  enough, then you can show that $x = A(t)x$ is exponentially stable
  (beyond the scope of this course).

Today we'll be looking just at Lyapunov as it applies to the time-invariant
case. We spend a third of EE 222 studying Lyapunov theory and its
variations and how to construct Lyapunov functions. Most exportable: use of
external functions to avoid needing to integrate the system itself.

This leads us to our last test: a taste of what Lyapunov theory
is.

Theorem (Lyapunov condition for exponential stability of $\dot{x} = Ax$)
------------------------------------------------------------------------

We consider the following matrix equation (the **Lyapunov equation**) $A^TP
+ PA = -Q$, where $P,Q$ are square matrices. Theorem: the system is
exponentially stable iff $\forall Q = Q^T > 0$ the Lyapunov equation has a
unique solution $P = P^T > 0$.

Consider $\fn{V}{\Re^n}{\Re^n} = x^TPx$, where for $Q = Q^T > 0$, $P = P^T
> 0$ is the solution to the Lyapunov equation.

We're going to look at $\dot{V}$ (this is the same derivative as before,
the **Lie derivative**: wherever we see the time derivative of the state,
we apply the dynamics of the system). This derivative gives a measure of
how much $V(x)$ is changing along the trajectories of the system. It
suffices to say that $\dot{x}$ represents the dynamics of the system.

So $\dot{V} = x^TA^TPx + x^TPax = x^T(A^TP + PA)x = -x^TQx$. What we want
to do is relate the changes in $V$ back to the changes in $x$. As before,
$\dot{V}(x) = -x^TQx  \ge -\lambda_{\min}(Q)\mag{x}^2$. Note that $-\mag{x}^2
\le -\frac{V(x}{\lambda_{\max}(P)}$, and so we can proceed as before.

This in itself is an important result. More of a technique for analysis
than something that you'd use for assessing stability. The introduction of
a Lyapunov function with a specific form (a positive definite function
whose Lie derivative is a negative definite function) is what's useful.

Often the work in using Lyapunov theory is to construct such functions. In
linear system it's easy because it's just given to you.

(four equivalent statements, proven in Callier and Desoer -- one of these
is that if one Q exists such that this holds, then it holds for all Q)

Controllability / Observability
-------------------------------

Motivation: designing and manipulating the system so you can get it to do
a host of things. What we're going to launch into in the last part of the
class: understanding what controllability of a system means. Part of that
question is whether or not we can sufficiently observe the dynamics of the
system through the output. That tells us how well we can control the
system. Given that, we go on to ponder how to design controllers; we'll use
the feedback topology we've seen twice already.

Two parts: assessment of controllability of systems, controller design.

In the last ten minutes: intuitive discussion about what controllability
and observability mean. These are general to dynamic systems (not specific
to linear systems).

Recall our definition of dynamical systems: five-tuple representation $D =
(\mathcal{U}, \Sigma, \mathcal{Y}, s,r)$, semigroup and state transition
axioms hold. The input is said to **steer** the initial condition $x_0$ @
$t_0$ to $x_1$ @ $t_1$ if $x_1 = s(t_1, t_0, x_0, u)$.

We say that D is **controllable** on some time interval if $\forall x_0, x_1
\in \Sigma \exists u \in \mathcal{U}$ such that $u$ steers $x_0$ @ $t_0$ to
$x_1$ @ $t_1$.

We define controllability to be specific on a time interval. **completely
controllable** (cc) denotes that the system is controllable on all time (if
controllability is not indicated with an interval, it usually denotes
complete controllability). Controllability of the system corresponds to
surjectivity of the state transition function, i.e. $\forall x_0 \in
\Sigma, \fn{s(t_1, t_0, x_0, \cdot)}{U}{\Sigma}$ is surjective.

We'll start next day by talking about observability and thinking about more
specific tests.
