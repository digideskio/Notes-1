Introduction to dynamical systems
=================================
September 20, 2012
------------------

Suppose we have equations $\dot{x} = f(x, u, t)$, $\fn{f}{\Re^n \times
\Re^n \times \Re_+}{\Re^n}$ and $y = h(x, u, t)$, $\fn{h}{\Re^n \times
\Re^n \times \Re_+}{\Re^n}$. We define $n_i$ as the dimension of the input
space, $n_o$ as dimension of the output space, and $n$ as the dimension of
the state space.

We've looked at the form, and if we specify a particular $\bar{u}(t)$ over some
time interval of interest, then we can plug this into the right hand side
of this differential equation. Typically we do not supply a particular
input. Thinking about solutions to this differential equation, for now,
let's suppose that it's specified.

Suppose we have some feedback function of the state. If $u$ is specified,
as long as $\bar{f}$ satisfies the conditions for the existence and
uniqueness theorem, we have a differential equation we can solve.

Another example: instead of differential equation (which corresponds to
continuous time), we have a difference equation (which corresponds to
discrete time).

Example: dynamic system represented by an LRC circuit. One practical way to
define the state $x$ is as a vector of elements whose derivatives appear in
our differential equation. Not formal, but practical for this example.

Notions of discretizing.

What is a dynamical system?
---------------------------
As discussed in first lecture, we consider time $\tau$ to be a privileged
variable. Based on our definition of time, the inputs and outputs are all
functions of time.

Now we're going to define a **dynamical system** as a 5-tuple: $(\mathcal{U},
\Sigma, \mathcal{Y}, s, r)$ (input space, state space, output space, state
transition function, output map).

We define the **input space** as the set of input functions over time to an
input set $U$ (i.e. $\mathcal{U} = \{\fn{u}{\tau}{U}\}$. Typically, $U =
\Re^{n_i}$).

We also define the **output space** as the set of output functions over time to
an output set $Y$ (i.e. $\mathcal{Y} = \{\fn{y}{\tau}{Y}\}$). Typically, $Y
= \Re^{n_o}$.

$\Sigma$ is our **state space**. Not defined as the function, but the actual
state space. Typically, $\Sigma = \Re^n$, and we can go back and think
about the function $x(t) \in \Sigma$. $\fn{x}{\tau}{\Sigma}$ is called the
state trajectory.

$s$ is called the **state transition function** because it defines how the
state changes in response to time and the initial state and the
input. $\fn{s}{\tau \times \tau \times \Sigma \times U }{\Sigma}$. Usually
we write this as $x(t_1) = s(t_1, t_0, x_0, u)$, where $u$ is the function
$u(\cdot) |_{t_0}^{t_1}$. This is important: coming towards how we define
state. Only things you need to get to state at the new time are the initial
state, inputs, and dynamics.

Finally, we have this **output map** (sometimes called the readout map)
$r$. $\fn{r}{\tau \times \Sigma \times U}{Y}$. That is, we can think about
$y(t) = r(t, x(t), u(t))$. There's something fundamentally different
between $r$ and $s$. $s$ depended on the function $u$, whereas $r$ only
depended on the current value of $u$ at a particular time.

$s$ captures dynamics, while $r$ is static. Remark: $s$ has dynamics
(memory) -- things that depend on previous time, whereas $r$ is static:
everything it depends on is at the current time (memoryless).

In order to be a dynamical system, we need to satisfy two axioms: a
dynamical system is a five-tuple with the following two axioms:

* The **state transition axiom**: $\forall t_1 \ge t_0$, given $u, \tilde{u}$
  that are equal to each other over a particular time interval, the state
  transition functions must be equal over that interval, i.e. $s(t_1, t_0,
  x_0, u) = s(t_1, t_0, x_0, \tilde{u})$. Requires us to not have
  dependence on the input outside of the time interval of interest.
* The **semigroup axiom**: suppose you start a system at $t_0$ and evolve it to
  $t_2$, and you're considering the state. You have an input $u$ defined
  over the whole time interval. If you were to look at an intermediate
  point $t_1$, and you computed the state at $t_1$ via the state transition
  function, we can split our time interval into two intervals, and we can
  compute the result any way we like. Stated as the following: $s(t_2, t_1,
  s(t_1, t_0, x_0, u), u) = s(t_2, t_0, x_0, u)$.

When we talk about a dynamical system, we have to satisfy these axioms.

Response function
-----------------
Since we're interested in the outputs and not the states, we can define
what we call the **response map**. It's  not considered part of the definition
of a dynamical system because it can be easily derived.

It's the composition of the state transition function and the readout map,
i.e. $y(t) = r(t, x(t), u(t)) = r(t, s(t, t_0, x_0, u), u(t)) \defequals
\rho(t, t_0, x_0, u)$. This is an important function because it is used to
define properties of a dynamical system. Why is that? We've said that
states are somehow mysterious. Not something we typically care about:
typically we care about the outputs. Thus we define properties like
linearity and time invariance.

Time Invariance
---------------
We define a time-shift operator $\fn{T_\tau}{\mathcal{U}}{\mathcal{U}}$,
$\fn{T_\tau}{\mathcal{Y}}{\mathcal{Y}}$. $(T_\tau u)(t) \defequals u(t -
\tau)$. Namely, the value of $T_\tau u$ is that of the old signal at
$t-\tau$.

A **time-invariant** (dynamical) system is one in which the input space and
output space are closed under $T_\tau$ for all $\tau$, and $\rho(t, t_0,
x_0, u) = \rho(t + \tau, t_0 + \tau, x_0, T_\tau u)$.

Linearity
---------
A **linear** dynamical system is one in which the input, state, and output
spaces are all linear spaces over the same field $\mathbb{F}$, and the
response map $\rho$ is a linear map of $\Sigma \times \mathcal{U}$ into
$\mathcal{Y}$.

This is a strict requirement: you have to check that the response map
satisfies these conditions. Question that comes up: why do we define
linearity of a dynamical system in terms of linearity of the response and
not the state transition function? Goes back to a system being
intrinsically defined by its inputs and outputs. Often states, you can have
many different ways to define states. Typically we can't see all of
them. It's accepted that when we talk about a system and think about its
I/O relations, it makes sense that we define linearity in terms of this
memory function of the system, as opposed to the state transition function.

Let's just say a few remarks about this: **zero-input response**,
**zero-state response**. If we look at the zero element in our spaces (so
we have a zero vector), then we can take our superposition, which implies
that the response at time $t$ is equal to the zero-state response, which is
the response, given that we started at the zero state, plus the zero input
response.

That is: $\rho(t, t_0, x_0, u) = \rho(t, t_0, \theta_x, u) + \rho(t, t_0,
x_0, \theta_u)$ (from the definition of linearity).

The second remark is that the zero-state response is linear in the input,
and similarly, the zero-input response is linear in the state.

One more property of dynamical systems before we finish: **equivalence** (a
property derived from the definition). Take two dynamical systems $D = (U,
\Sigma, Y, s, r), \tilde{D} = (U, \bar{\Sigma}, Y, \bar{s}, \bar{r})$. $x_0
\in D$ is equivalent to $\tilde{x_0} \in \tilde{D}$ at $t_0$. If $\forall t
\ge t_0, \rho(t, t_0, x_0, u) = \tilde{\rho}(t, t_0, \tilde{x_0}, u)$
$\forall x$ and some $\tilde{x}$, the two systems are equivalent.
