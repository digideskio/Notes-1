Functions and Vector Spaces
===========================
August 28, 2012
---------------

OH: M/W 5-6, 258 Cory

Today: beginning of the course: review of lin. alg topics needed for the
course. We're going to go through lecture notes 2 and probably start on
the third sets of notes. Will bring copies of 3 and 4 on Thursday.

We did an introduction to notation and topics last time. First topic:
functions, which will be used synonymously with "maps". Terminology will be
used interchangeably.

Given two sets of elements X, Y, we defined $\fn{f}{X}{Y}$. Notion of
range vs. codomain (range is merely the subset of the codomain covered by
f). We define $f(X) \defequals \set{f(x)}{x \in X}$ to be the
range.

Properties of functions
-----------------------

Injectivity of functions ("one-to-one"). A function $f$ is said to be
injective iff the function maps each x in X to a distinct y in
Y. Equivalently, $f(x_1) = f(x_2) \iff x_1 = x_2$. This is also equivalent
to $x_1 \neq x_2 \iff f(x_1) \neq f(x_2)$.

Surjectivity of functions ("onto"). A function $f$ is said to be surjective
if the codomain is equal to the range. Basically, the map $f$ covers the
entire codomain. A way to write this formally is that $f$ is surjective iff
$\forall y \in Y \exists x \in X \ni y = f(x)$.

And then a map $f$ is bijective iff it is both injective and surjective. We
can write this formally as there being a unique $x \in X$ forall $y \in Y$.

Example: inverse of a map. We can talk about left and right inverses of
maps. Suppose we have a map $\fn{f}{X}{Y}$. We're going to define this
map $\mathbb{1}_X$ as the identity map on X. Namely, application of this
map to any $x \in X$ will yield the same $x$.

The left inverse of $f$ is $\fn{g_L}{Y}{X}$ such that $g_L \circ f =
\mathbb{1}_X$. In other words, $\forall x\in X, (g_L \circ f)(x) = x$.

Prove: $f$ has a left inverse $g_L$ iff $f$ is injective. First of all, let
us prove the backwards implication. Assume $f$ is injective. Prove that
$g_L$ exists. We're going to construct the map $\fn{g_L}{Y}{X}$ as
$g_L(f(x)) = x$, where the domain here is the range of $f$. In order for
this to be a well-defined function, we require that $x$ is unique, which is
met by injectivity of $f$.

Now let us prove the forward implication. Assume that this left inverse
$g_L$ exists. By definition, $g_L \circ f = \mathbb{1}_x \iff \forall x
\in X g_L(f(x)) = x$. If $f$ were not injective, then $g_L$ would not be
well-defined ($\exists x_1 \neq x_2$ such that $f(x_1) = f(x_2)$, and so
$g_L$ is no longer a function).

review: contrapositive: $(A \implies B) \iff (\lnot B \implies \lnot A)$;
contradiction: $(A \not\implies B) \implies \text{contradiction}$. 

We can similarly shows surjectivity $\iff$ existence of a right
inverse. With these two, we can then trivially show that bijectivity $\iff$
existence of an inverse (rather, both a left and right inverse, which we
can easily show must be equal). Proof will likely be part of the first
homework assignment.

Fields
------
We need the definition of a vector and a field in order to define a vector
space.

A field is an object: a set of elements $S$ with two closed binary
operations defined upon $S$. These two operations are addition (which
forms an abelian group over $S$) and multiplication (which forms an abelian
group over $S - \{0\}$) such that multiplication distributes over
addition. Note that convention dictates $0$ to be the additive identity and
$1$ to be the multiplicative identity.

Other silly proofs include showing that if both a left and right identity
exist, they must be equivalent, or that multiplication by $0$ maps any
element to $0$.

Vector spaces (linear spaces)
-----------------------------

A vector space is a set of vectors V and a field of scalars $\mathbb{F}$,
combined with vector addition and scalar multiplication. Vector addition
forms an abelian group, but this time, scalar multiplication has the
properties of a monoid (existence of an identity and associativity). We
then have the distributive laws $\alpha + \beta)x = \alpha x + \beta x$ and
$\alpha (x + y)$.

Function spaces
---------------

We define a space $F(D,V)$, where $(V, \mathbb{F})$ is a vector space and
$D$ is a set. $F$ is the set of all functions $F(D, V) = \fn{f}{D}{V}$. Is
$(F, \mathbb{F})$ a vector space (yes) where vector addition is pointwise
addition of functions and scalar multiplication is pointwise multiplication
by a scalar?

Examples of this: space of continuous functions on the closed interval
$\fn{\mathcal{C}}{\bracks{t_0, t_1}}{\Re^n}$, ($(C(\bracks{t_0, t_1},
\Re^n), \Re)$). This is indeed a vector space.

Lebesgue spaces
---------------

$L_p t_0, t_1) = \set{\fn{f}{[t_0, t_1]}{\Re}}{\int_{t_0}^{t_1}
\abs{f(t)}^p dt < \infty}$.

We can then talk about $\ell_p$, which are spaces of sequences. $\ell_2$ is
the space of square-summable sequences of real numbers. Informally, $\ell_2
= \set{ v = \{v_1, v_2, ... v_k\}}{v_k \in \Re \sum_k \abs{v_k}^2 <
\infty}$.

In general, when looking at vector spaces, often we use $\mathbb{F} = \Re$,
and we refer to the space as simply $V$.

Next: subspaces, bases, linear dependence/independence, linearity. One of
the main things we're going to do is look at properties of linear functions
and representation as multiplication by matrices.
