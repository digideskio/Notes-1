CS 191: Qubits, Quantum Mechanics and Computers
===============================================
Free particles, Uncertainty, Quantization
-----------------------------------------
Feb 21, 2012
------------

We talked about things informally last time, and what we were going to do
was see Schrödinger's equation from various viewpoints.

Today, again we'll look at a free particle in one dimension, a somewhat
more rigorous of the uncertainty relation, quantization, and use that as
our first implementation of a qubit.

What we want to do is describe how this state evolves in time. This is what
was described by Schrödinger's equation. Last time, we derived what this
equation should look like (approximately) as a result of certain
considerations.

Clasically, the energy of this particle (which we'll write as a function of
two parameters $p$ and $x$). The Schrödinger equation thus tells us that
$i\hbar \pderiv{\psi}{t} = \frac{p^2}{2m} + V(x)$.

So, first of all, we want to figure out what corresponds to the position in
quantum mechanics. How do you measure the position of this particle? We
said we had a position operator, and when you applied it to $\psi(x)$, what
you got back was $x\psi(x)$. This is the same idea of measurables as
before: we're measuring position, so our eigenvalues correspond to the
position of the particle. What we are requiring from our position operator
is exactly the same thing.

So the momentum operator $\hat{p}$ is $\frac{\hbar}{i}
\pderiv{}{x}$. $\hbar$ is the reduced Planck's constant. Again, the
discrete analogue of this is a measurable. Once again, we're ignoring
constants, since we don't really care about constants.

What the correspondence principle says is that what you should do (when you
know what the classical situation looks like) is to just substitute
$\hat{x}$ and $\hat{p}$ instead of $x$ and $p$, and put that down for your
energy operator. So why do you do this? Better people than us have done
this in the past, and it seemed to work out for them.

So clearly, what Schrödinger's equation must say is: $i\hbar
\pderiv{\psi}{t} = -\frac{\hbar^2}{2m} \pderiv{^2\psi}{x^2}$.

(ignoring potential energy as a result of it being a free particle -- it is
not subject to any potential; potential is equivalent to 0.)

Uncertainty
===========

Let's just try to see how our function (given as a function of $x$) looks
as a function of p. What we said last time was that was the Fourier
transform. The fourier basis and standard basis are "like oil and water" --
if one is maximally certain, then the other is maximally uncertain (Fourier
time-frequency uncertainty principle -- a useful exercise is to take the
Fourier transform of a Gaussian, which remains a Gaussian in both
spaces). So you cannot come up with any wave function that is localized in
both spaces. We can try to quantify this. We had nice pictures, but now
we're going to work directly with operators. It's going to be not vague and
very precise, so for some, it'll be great. But for others, it'll be a
disaster since there are no pictures. (( For those of you reading at home,
there are no pictures yet in this version. Sorry! - ed.))

Remember: the thing about an observable that we care about most is the
eigenvector decomposition. So the question is: what do the eigenvectors
look like? That determines how nicely they play with each other.

Discrete case first. Remember you had your phase-flip operator $Z$ and
bit-flip operator $X$. Considering the eigenvectors and eigenvalues, the
claim is that this is as good as you are going to get.

Another way to measure how different these eigenvectors are is to see
whether these matrices commute or not. If they commute, they have a common
set of eigenvectors. Commuting means $XZ - ZX = 0$. So we want to look at $XZ
- ZX$ (a commutator, denoted by $\comm{X}{Z}$).

So what does this look like between $\hat{x}$ and $\hat{p}$? We have
product rule coming into play... yielding $\comm{x}{p} \equiv i\hbar$.

We'll use this to derive $\Delta x\Delta p = \frac{\hbar}{2}$. We'll do
this quickly so we'll have time to talk about the particle in a box.

Recall: given an observable $A$ and a state $\ket{\psi}$, the expected
value is $\braKet{\psi}{A}{\psi}$. We also saw that the variance was
$E(x^2) - E(x)^2$, so in this case $\sigma^2 = \braKet{\psi}{A^2}{\psi} -
\braKet{\psi}{A}{\psi}$.

For now, assume $\braKet{\psi}{A}{\psi} = 0$. Makes derivation simpler, and
we're just asserting that we don't really lose much (anything, really).

Take $\Psi \equiv A\ket{\psi}, \Phi \equiv B\ket{\psi}$. By Cauchy-Schwarz,
we have that this is greater than or equal to $\ket{\Psi}{\Phi} =
\braKet{\psi}{AB}{\psi}$. By symmetry, it's also greater than or equal to
$\ket{\Phi}{\Psi} = \braKet{\psi}{BA}{\psi}$. As a result, $(\Delta
A)^2(\Delta B)^2 \ge \abs{\frac{1}{2}\braKet{\psi}{AB-BA}{\psi}}^2 =
\abs{\frac{1}{2}\braKet{\psi}{\comm{A}{B}}{\psi}}^2 = \abs{\frac{1}{2}
\braKet{\psi}{i\hbar}{\psi}}^2 = \frac{\hbar^2}{4}$. So the square of the
spread of $x$ plus the square of spread of momentum is at least
$\frac{\hbar^2}{4}$. If you take square roots, you get the proper
result. (Note: You can get a better bound by being more careful by also
using the anticommutator. We were being sloppy for the purpose of making
things simpler.)

As noted earlier, this uncertainty principle actually arises directly from
the Fourier time-frequency uncertainty principle. We can also generalize
this principle to any two quantities, not just transform pairs, but that is
outside of the scope of this course.

Particle in a box
=================
This is basically just the infinite square well. We want to figure out our
eigenfunctions just by looking at the operator. Again the way we do this is
guess and come up with the right answer by chance. You expect the
eigenfunction to be an exponential, so we guess and check. Life is nice
that way.

We are trying to solve for $H\ket{\phi} + E\ket{\phi}$. Guess that
$\ket{\phi} = e^{ikx}$. Let's figure this out. Our maneuver is to say that
we're dealing with a separable equation ("decompose this problem" by
looking at the eigenvectors of $H$).

Suppose our state was one of these eigenvectors. We then know what the
Hamiltonian does to it: it simply applies a scalar (the corresponding
energy level). So of course we want to write our function in this basis,
since we know how to solve the simpler differential equation.

The operator affects each eigenvector separately. So we can tack on the
time dependence as an afterthought (to each eigenvector).

Coming up
=========

We'll solve this problem using this very strategy. We know what the
eventual answer looks like: $\sum e^{-iEt/\hbar}\ket{\psi(x)}$.
