CS 191: Qubits, Quantum Mechanics and Computers
===============================================
Observables, Schrodinger's equation -- Feb 7, 2012
---------------------------------------------------

Observable
==========

Operator (i.e. can be described by a matrix) that describes any quantity
that can be measured, like energy, position, or spin. You feed in a quantum
state and receive as output a real number.

Why an operator? If you have a k-level system, then an observable for this
would be a k-by-k Hermitian matrix (i.e. $A = A^\dagger$). Important thing
about Hermitian matrices: spectral theorem: orthonormal eigenbasis of
eigenvectors $\phi$ that correspond to real eigenvalues $\lambda$.

The real number you get as a result of the measurement -- what you read out
in the measurement outcome -- is $\lambda$. Consider discrete energy
levels; after a measurement, we collapse the wave function into a single
eigenstate.

We already knew what a measurement was. So what happened here, how can we
have a new definition of a measurement? This isn't fair. How can you trust
a course that changes its mind every other week? No complaints? I mean,
isn't it terrible? This is completely different. So what's going on?

Our previous notion of measurement required us to choose some orthonormal
basis. We write out our state $\Psi$ in this basis. The result of the
measurement was equal to i with probability $\abs{\beta i}^2$, and the new
state was $\ket{\Psi_i}$. So how does this correspond to what we have now?

We can reconcile them by showing that our old notion was less
formalized. It's only that basis which corresponds to the basis vectors of
some Hermitian matrix.

Pick any arbitrary orthonormal set of vectors and an arbitrary set of real
numbers. Ask: is there any matrix that has these eigenvectors and these
eigenvalues? Argue: always possible. In that sense, the new definition of a
measurement is really the same as the old one.

Consider case where eigenvalues not unique: reconsider notion of
orthonormal eigenvectors as notion of orthonormal eigenspaces. We've seen
an example of this, by the way: when we had a two-qubit system and we only
measured the first qubit. Each of the two outcomes corresponded to a
two-dimensional subspace. There were two eigenvectors with the same
eigenvalue. Project the subspace onto the space spanned by eigenstates
corresponding to result of measurement.

Reasoning: in the general case, you don't project onto a basis vector; you
project onto the subspace that is consistent with the outcome of the
measurement.

What the measurement does is provide some information about the state and
change the state to reflect the outcome. It doesn't restrict itself any
more than it has to.

Diagonalization: converting to a different basis, scaling appropriately,
converting back to the original basis.

A way to construct the operator (must be a hermitian matrix) is with an
outer product: you can generate the change-of-basis matrix.

Schrodinger's Equation
======================

This is the most basic equation in quantum mechanics; it describes how a
system evolves over time. It depends on one particular operator, the
Hamiltonian: the energy operator (more specifically, the sum of kinetic
energy $T$ and potential energy $V$). When you write out the Hamiltonian of
this system, the eigenvectors correspond to (eigen)states with definite
energy. The corresponding eigenvalue $E_i$ is the corresponding energy.

So now what Schrodinger's equation says is that the state $\ket{\psi}$ of
the system is a function of time, and it evolves according to a
differential equation which relates the energy of the system.

$i\hbar \pderiv{\psi}{t} = \hat{H} \psi$ ($\hbar \equiv$ reduced Planck's
constant, $i \equiv \sqrt{-1}$)

The rate of change depends on what the Hamiltonian tells us to do. You can
consider the Hamiltonian talking about interaction between parts of the
system or between subsystems. Forces. Everything.

Now, Schrodinger actually discovered this equation in 1926. This was after
many of the initial discoveries in quantum mechanics. It was after
de Broglie discovered the wave-particle duality. One of the biggest
intellectual events of the twentieth century.

So let's see what this equation tells us about the equations of motion.

So what we know is that if the state at time 0 was an eigenvector $\phi$,
then the state at time $t$ must be some constant $A(t)\phi$.

Precession of individual states; generalization is the summation of the
various eigenstates. If you want to write out the linear operator that
tells you how to go from $\Psi(x,0)$ to $\Psi(x,t)$, it's just the diagonal
matrix of eigenvalues. You can check that this is a unitary matrix.

The way you write this unitary matrix in notation is $\exp(-i\lambda
t/\hbar)$. Nothing to be scared by. Look, we're exponentiating a matrix,
but that's nothing to be worried about.

Suppose $\psi(0)$ = $\ket{0}$, and you wanted to know $\psi(t)$. Then we
just perform the procedure outlined above.

In more detail:

We consider the eigenstates of energy to be stationary states: if we are in
an eigenstate of energy $\ket{\phi_i}$ (as is the case after making a
measurement of energy), then we will always be in that state. From the wave
equation, we see that our equation of state is $\ket{\phi_i} e^{-iE_i
t/\hbar}$, up to an overall phase. Since overall phases are irrelevant to
quantum mechanics (only relative phases are significant), once in this
specific state, we will always be in this state (until some perturbation of
our system).

Now, what does this tell us? We can decompose our state $\ket{\psi(0)}$
into our Hamiltonian's eigenbasis, and each state will evolve in the
manner described above.
