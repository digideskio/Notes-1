CS 191: Qubits, Quantum Mechanics and Computers
===============================================
Observables, Schrödinger's equation -- Feb 7, 2012
---------------------------------------------------

Observable
==========

Operator (i.e. can be described by a matrix) that describes any quantity
that can be measured, like energy, position, or spin. You feed in a quantum
state and receive as output a real number.

Why an operator? If you have a k-level system, then an observable for this
would be a k-by-k Hermitian matrix (i.e. $A = A^\dag$). Important thing
about hermitian matrices: spectral theorem: orthonormal set of eigenvectors
\phi that correspond to real eigenvalues \lambda.

The real number you get as a result of the measurement -- what you read out
in the measurement outcome -- is \lambda. Consider discrete energy levels;
after a measurement, we collapse the wave function into a single
eigenstate.

We already knew what a measurement was. So what happened here, how can we
have a new definition of a measurement? This isn't fair. How can you trust
a course that changes its mind every other week? No complaints? I mean,
isn't it terrible? This is completely different. So what's going on?

Our previous notion of measurement required us to choose some orthonormal
basis. We write out our state \Psi in this basis. The result of the
measurement was equal to i with probability \abs{\beta i}^2, and the new
state was {\Psi i}. So how does this correspond to what we have now?

We can reconcile them by showing that our old notion was less
formalized. It's only that basis which corresponds to the basis vectors of
some Hermitian matrix.

Pick any arbitrary orthonormal set of vectors and an arbitrary set of real
numbers. Ask: is there any matrix that has these eigenvectors and these
eigenvalues? Argue: always possible. In that sense, the new definition of a
measurement is really the same as the old one.

Consider case whereeigenvalues not unique: reconsider notion of orthonormal
eigenvectors as notion of orthonormal eigenspaces. We've seen an example of
this, by the way: when we had a two-qubit system and we only measured the
first qubit. Each of the two outcomes corresponded to a two-dimensional
subspace. There were two eigenvectors with the same eigenvalue. Project the
subspace onto the space spanned by eigenstates corresponding to result of
measurement.

Reasoning: in the general case, you don't project onto a basis vector; you
project onto the subspace that is consistent with the outcome of the
measurement.

What the measurement does is provide some information about the state and
change the state to reflect the outcome. It doesn't restrict itself any
more than it has to.

diagonalization: converting to a different basis, scaling appropriately,
converting back to the original basis.

A way to construct the operator (must be a hermitian matrix) is with an
outer product: you can generate the change-of-basis matrix.

==== Intermission =====

Piazza: posted question about other people wanting midterm moved. Enough
objections such that we will stick with original date: next Tuesday. Posted
yesterday a homework which is effectively a review for the midterm, which
will cover everything up until this lecture. Three problems on homework: 2
are review, 1 is on today's lecture. **Due this Friday at 5.**

Schrödinger's Equation
======================

Most basic equation in quantum mechanics; describes how a system evolves
over time. Depends on one particular operator, the Hamiltonian: the energy
operator (more specifically, kinetic energy T + potential V). When you
write out the Hamiltonian of this system, the eigenvectors correspond to
(eigen)states with definite energy. The corresponding eigenvalue E{i} is
the corresponding energy.

So now what Schrödinger's equation says is that the state \psi of the
system is a function of t, and it evolves according to a differential
equation which relates the energy of the system.

i\hbar \pderiv{\psi}{t} = \hat{H} \psi
(\hbar \equiv Planck's constant, i \equiv \sqrt{-1}

The rate of change depends on what the Hamiltonian tells us to do. You can
consider the Hamiltonian talking about interaction between parts of the
system or between subsystems. Forces. Everything.

Now, Schrödinger actually discovered this equation in 1926. This was after
many of the initial discoveries in quantum mechanics. It was after
deBroglie discovered the wave-particle duality. One of the biggest
intellectual events of the twentieth century.

So let's see what this equation tells us about the equations of motion. PDE
solving, yay.

So what we know is that if the state at time 0 was an eigenvector \phi,
then the state at time t must be some constant A(t)\phi.

precession of individual states; generalization is the summation of the
various eigenstates. If you want to write out the linear operator that
tells you how to go from \Psi(x,0) to \Psi(x,t), it's just the diagonal
matrix of eigenvalues. You can check that this is a unitary matrix.

The way you write this unitary matrix in notation is exp(-i\lambda
t/\hbar). Nothing to be scared by. Look, we're exponentiating a matrix, but
that's nothing to be worried about.

Suppose \psi(0) = \ket{0}, and you wanted to know \psi(t).
