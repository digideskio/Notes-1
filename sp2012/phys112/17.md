Physics 112: Statistical Mechanics
==================================
Partition Function. Mar 2, 2012
-------------------------------

# Midterm
  * Office hours
# Partition function as computational tool
# Ideal gas

We are looking at a totally different method of computing entropy. Instead
of the microcanonical method -- counting states (impose U; difficult), Then
we are putting the system in contact with a reservoir. We came to the
conclusion that $\prob{i} = \frac{1}{Z}e^{-\epsilon_i/\tau}$. So that's a
totally different method, which tends to be much easier.

From what you have seen, it is quite easy to get ahold of the thermodynamic
quantities you know of.

$$
\sigma = \pderiv{\tau\log Z}{\tau}
\\ F =  U - \tau\sigma = -\tau\log Z \implies \sigma = -\pderiv{F}{\tau}
\\ U = \avg{\epsilon} = \sum \epsilon_i p_i = \tau^2 \pderiv{\log Z}{\tau}
= -\tau^2\pderiv{\frac{F}{\tau}}{\tau}
$$

Examples
--------

Consider a two-level system with energies 0 and $\epsilon$. $Z = 1 +
e^{-\epsilon/\tau}$, trivially. Therefore $U = \tau^2\pderiv{\log z}{\tau}
= \tau^2\frac{\frac{1}{\tau^2}e^{-\epsilon/\tau}}{1 + e^{-\epsilon/\tau}} =
\frac{1}{e^{\epsilon/\tau} + 1}$.

Now, for an ideal gas: $Z = \sum_s e^{-\epsilon_s/\tau} = \int \frac{d^3q
d^3p}{\hbar^3}e^{-\epsilon}{\tau}$. Phase space integral. Things are very
simple.

This is equivalent to $\frac{V}{\hbar^3}\int dp_x e^{-p_x^2/2M\tau} dp_y
e^{-p_y^2/2M\tau} dp_z e^{-p_z^2/2M\tau} = \frac{V}{\hbar^3}\left(
\sqrt{2\pi M\tau}\right)^3 = V\left(\frac{2\pi M\tau}{\hbar^2}\right)^3/2 =
n_Q$.

$\avg{\epsilon} = \frac{3}{2} \frac{\tau^2}{\tau} = \frac{3}{2}\tau$

The power of $Z$ is that either you can do these sums very easily
(e.g. geometric series), or the terms grow so fast that you can just take
the first term, or you can use the integral approximation as we have done
here.

Harmonic Oscillator
-------------------

$E = \sum e^{-s\hbar\omega/\tau} = \left(\sum e^{-\hbar\omega/\tau}
\right)^s = \frac{1}{1 - e^{\hbar\omega/\tau}}$

These are known as the canonical methods, which are fairly powerful. I may
come back to this question of density of states. I have probably told you
enough on how to sum over discrete states. We may come back when we review
the material.

I have spoken long enough about this fairly technical thing. Let's ask
ourselves how to extend this to multiple systems (e.g. 2).

The partition function of 2 systems is merely the product if the systems
are distinguishable, and the product divided by $2!$ (approximately) if
they are indistinguishable. Consider indistinguishability of "quantum
states", where each state is a system.

Therefore if we have N indistinguishable systems, $Z(N) \approx \frac{1}
{N!} Z(1)^N$. This is a low occupation number approximation due to Gibbs.

$$Z_1 = e^{-mB/\tau} + e^{mB/\tau} = 2\cosh\frac{mB}{\tau} \\ Z = Z_1^N =
2^N\cosh^N\frac{mB}{\tau} \implies U = -NmB\tanh\frac{mb}{\tau}.$$

Thus $M = \frac{U}{BV} = nm\tanh\frac{mB}{\tau}$.

[ curie temperature: where M disappears ]

* Why is the division of the product by N! approximate?

As mentioned earlier, this is a low concentration approximation, i.e. the
probability of having two systems in the same state is negligible. The
error we accumulate is due to fewer terms appearing in the sum.

In other words, we have very weak correlation coefficients.
