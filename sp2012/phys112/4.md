Physics 112: Statistical Mechanics
==================================
Kinetic Theory 3 / Probabilities. January 27, 2012
--------------------------------------------------

Various probability stuffs. Continuous distirbutions. Sum/average of
independent events. Central limit theorem.

$$
  P(s) \ge 0, \sum P(s) = 1
  \\ \avg{y} = \sum y(s)P(s) \text{ [ this is the first moment. ]}
  \\ y(s) = 35 \delta_{ik}. \avg{y} = \sum 35\delta_{ik} = 35/38.
$$

Variance:

  $\sigma^2 = \avg{(y(s) - 〈y})^2 = \avg{y^2} - 2\avg{y\avg{y}} + \avg{y}^2
  = \avg{y^2} - \avg{y}^2$

root mean square (rms) $\equiv$ standard deviation

Independence. Usually, if I have two random variables, x and y, the
probability of $P(x,y) = P(x|y)P(y) \neq P(x) \times P(y)$. We say we have
independence iff $P(x,y) = P(x)P(y)$. In other words, $P(x|y) = P(x)$.

You can define a correlation coefficient to be
  $\frac{(x - \avg{x})(y - \avg{y})}{\sigma_x\sigma_y}$.

Independence $ ⇒ \rho = 0$. Converse not necessarily true.

Continuous distributions. Histograms. The case where a variable is
continuous. We now have probability _densities_.

$$
  f(x)dx = g(y)dy = f(x,y)\deriv{x}{y}dy.
  f(x) \ge 0, \sum f(x)dx = 1.
$$

Moments: we can define moments in exactly the same way as before.
The moment of a variable $y(x)$

$$
\avg{y(x)} = \int y(x)f(x)dx.
\\ \mu = \avg{x} = \int xf(x)dx.
\\ \sigma^2 = \avg{x²} - \avg{x}² = \int x^2 f(x)dx - \parens{\int xf(x)dx}^2.
$$

$f(x,y)dxdy = g(x)dx h(y)dy$. Factoring works the same way, if our
variables are independent.

Normal distributions: Gaussian.

It is very important to put the differential element ($dx$ or $dy$) because
the function changes depending on what the differential element is. The
histogram depends on what variable you choose to plot. If I choose $x$ or
$x^2$, my histogram will be different. Usually.

The mean is in the middle of a normal distribution because the third
moment is 0.

Full-width half maximum (FWHM) $\approx 2.3\sigma$

A is called the mode, i.e. the maximum. In a distribution with nonzero skew
(like the Maxwell-Boltzmann), the mode is different from the mean.

mean: location.

standard deviation: width.

skewness: symmetry.

kurtosis: peakedness.

Fourier transform is the characteristic function. The log of this is stuff
with cumulants.

Sum of random variables:

$$
x \equiv y + z
\\ \avg{x} = \avg{y} + \avg{z}.
\\ \sigma^2_x = \sigma^2_y + \sigma^2_z + 2\rho\sigma_y\sigma_z.
\\ \text{Independence} \implies \rho = 0; \sigma^2_x = \sigma^2_y + \sigma^2_z
\\ h(x)dx = (f*g)(x)dx \implies \text{the cumulants add!}
$$

Proof: Convolution in original space is equivalent to product in Fourier
space. Hence for a sum, the characteristic functions multiply and the logs
of characteristic functions add.

Central limit theorem: Cool if our variables actually are independent.
