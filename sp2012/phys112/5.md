Physics 112: Statistical Mechanics
==================================
Entropy and Stuff. January 30, 2012
-----------------------------------
Homework
========
First one is due today, second one is posted.

Central Limit Theorem
=====================

Taking N independent random variables $x_i$ of average $\mu_0$ and of
variance $\sigma_0^2$, the experimental average $A = \frac{1}{N}\sum
x_{i}$. $f(A)dA → \lim_{N\to\infty} \frac{1}{\sqrt{2\pi}σ}
\exp(-\frac{(A-\mu)^2}{2\sigma^2})dA; \mu = \mu_0, \sigma^2 =
\frac{\sigma_0^2}{N}.$

This is different from $\avg{A}$, which would just be an integral.

The other thing is that $\sigma^2 = \frac{\sigma_0^2}{N}$. The variance
decreases as $\frac{1}{N}$, or the standard deviation decreases as
$\frac{1}{\sqrt{N}}$. This is fairly typical of stochastic processes, where
the relative width decreases as $\frac{1}{\sqrt{N}}$. Overall width will
increase if you don't normalize, but relative width decreases.

The relative widths of kurtosis and skewness go to zero as we add more
terms.

Consequences for Thermodynamics
-------------------------------

Because of large number of particles, averages are very peaked around mean.

 * System well characterized by mean = "macroscopic quantity".
 * Fluctuations are very small.
 * Not a lot of difference between most probable value, mean value,
   and experimental value.

Dealing with systems with large degrees of freedom. Temperature, for
instance, is related largely to the kinetic energy of the particles. It
will be very well-defined and have very few fluctuations if we are just
measuring the mean of said particles, and it will be very peaked around the
mean.

The central limit theorem makes thermodynamics meaningful.

Quantum States of a System
==========================
States of a System
------------------
Not covering spins. ALso, marginal definition of entropy.

(mostly chapters 1 and 2 of Kittel and Kroemer)

 * States / COnfigurations
 * Probabilities fo States
   + Fundamental assumptions
   + Entropy
 * Counting States
 * Entropy of an ideal gas.

State = Quantum State.
 * Well-defined, unique.
 * Discrete ≠ "classical thermodynamcs" where entropy was depending on
   resolution ΔE.

Boltzmann for reasons that he did not fully understand arrived at the
conclusion that he had to have discrete states. This was before Planck and
quantum mechanics. Boltzmann was always doubting himself to the point that
he took his own life. So when you are a little bit despaired, think about
Boltzmann.

It's amazing that a guy like that who contributed so much to modern physics
was unsure of himself.

Configuration = Macroscopic specification of system

 * Macroscopic Variables
   + Extensive: U, S, F, H, V, N (not normalized)
   + Intensive: T, P, μ (chemical potential)
 * Not unique: depends on level of details needed.
 * Variables + constraints ⇒ not independent.

Many microstates (states) correspond to a single macrostate
(configuration).

Quantum Mechanics in 1 transparency
-----------------------------------
Fundamental postulates

 * State of one particle is characterized by a wave function.
 * Probability distribution = |Ψ(x,t)|^2 with 〈Ψ|Ψ〉 = ∫{Ψ(x)*}Ψ(x)dx = 1.
 * Physical quantity → Hermitian operator.
 * In general, not fixed outcome. Expected value of Ô = 〈Ψ|Ô|Ψ〉.
 * Eigenstate ≡ state with a fixed outcome e.g. Ô|Ψ〉 = o|Ψ〉, where o
   is a number.
 * A finite system has discrete eigenvalues.

1-dimensional case, infinitely deep square well. Solve via separation
of variables, construct Fourier series.

If you solve this equation, you can show that in that case, the wave
function has to go to 0 at the wall.

That's just a particle in a box. If you ask yourself what is the momentum
of this particle, this particle is actually a series of two momenta. It
does not have a well-defined momentum, since it is going back and forth.
