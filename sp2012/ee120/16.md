EE 120: Signals and Systems
===========================
$\mathcal{Z}$ Transform
=======================

Something we've been brushing under the carpet for a while is the set of
signals in which the Fourier transform is not defined.

So the Z transform is defined for discrete-time LTI systems. (discrete
analogue of the Laplace transform)

We know that the output is simply the convolution of the input with the
impulse response.

If we said that $h(n) = \alpha^n u(n)$, where $\abs{\alpha} > 1$, then we
know that this signal has no frequency response. However, behavior can be
well-defined even though you can't say anything about it in the frequency
domain.

For instance: if x is of finite duration, then you have a finite number of
terms in the convolution corresponding to the output signal. You can thus
talk about the output of this system for such an impulse: convolution is
perfectly well-defined, and $y(n)$ is finite for all n (and thus
well-defined).

Another situation: if x is right-sided (i.e. $x(n) = 0$ for $n < N$ -- may
also have zero values to the right of $N$, but to the left, it is zero),
what happens?

Note that causal signals are a subset of right-sided signals. If n is
anything smaller than zero, you are looking at a right-sided but not
necessarily causal signal.

In the convolution of two right-sided signals (or two left-sided signals,
even!), finitely many terms contribute. Therefore in these cases (input and
impulse response) we can define our output anywhere (i.e. finite, but not
necessarily bounded).

Finally, if x is bounded and h is absolutely summable, then the system is
BIBO-stable -- $y$ is finite, so it is also bounded.

$\ell^\infty = \set{ x : \mathbb{Z} \mapsto \mathbb{C} : x(n) < B_x <
\infty}$

Recall that $\ell^1 = \set{ h : \mathbb{Z} \mapsto \mathbb{C} : \sum
\abs{h(n)} < B_x < \infty }$

For DTFT, we applied $e^{i\omega n}$ to our system and observed that our
output was $H(\omega)e^{i\omega n}$, where we defined $H(\omega) = \sum_n
h(n)e^{-i\omega n}$.

We're going to now relax the constraint that $\abs{e^{i\omega n}} = 1$,
i.e. $\omega \in \mathbb{R}$. Now let $x(n) = z^n \ (z \in \mathbb{C})$. So
if I apply this signal to the system, what am I going to get?

$$
y(n) = \sum_m h(m)x(n-m) = \sum_m h(m)z^{n-m} = z^n\sum_m h(m)z^{-m}
\\ z^{-n} y(n) = \sum_m h(m)z^{-m} \equiv \hat{H}(z)
$$

This is called the transfer function of the system.

The transfer function for us will either be the Z-transform (if
discrete-time) or the Laplace transform (if continuous-time). For now we're
stuck with the Z-transform.

Notice the similarity of the format of these expressions. The main
difference is that now, I'm allowed to veer away from the unit circle. This
is an infinite sum, so just as with the Fourier transform, we must worry
about convergence.

With Z transforms and Laplace transforms, we can't get away from
convergence. Associated with this sort of expression is what we call a
region of convergence (RoC). Basically, region in the complex plane for
which this sum converges.

Going to brush aside a lot of subtleties regarding convergence. $R_h$ is
the region in the complex plane (i.e. the set of $z$) such that $\sum_m
\abs{h(m)z^{-m}} < \infty$. If the kernel of this sum is absolutely
summable, we say that we are in the region of convergence. The values of
$z$ for which this is true make up the region of convergence.

I can take any discrete-time function and talk about its Z-transform. Just
as with the Fourier-transform, I can talk about the FT of any function.

So what if I'm looking at $x(n) = \delta(n)$? $\hat{X}(z) = 1$ -- we only
have one value in our sum. $R_x = \mathbb{C}$. In other words, $0 \le
\abs{z}$.

$$
\delta(n-1) \ztrans z^{-1}\:\: (R_h = \set{z : 0 < \abs{z}})
\\ \delta(n+1) \ztrans z\:\: (R_h = \set{z : 0 \le \abs{z} < \infty})
$$

Now, two-point moving average: $\frac{1}{2}\parens{\delta(n) + \delta(n-1)}
\ztrans \frac{1 + z^{-1}}{2} = \frac{z + 1}{2z}\ (R_h = \set{z : 0 <
\abs{z}})$. Note that if this had been an anti-causal two-point moving
average, we'd include 0 and exclude infinity.

All of these signals so far are finite-duration signals (FIR filters).

**The radius of convergence of a function that has a finite region of
  support is the entire complex plane with the possible exception of zero,
  infinity, or both.**

Example of both: three-point moving average, centered at zero.

May have noticed already that region of convergence has a particular
convergence so far: all of these resemble a radius, and rational in z. Not
always the case, but these are most of the signals we'll work with. There's
a nice accounting between numerator and denominator that allows you to
determine where the region of convergence is.

Ex: $h(n) = \alpha^n u(n)$, $\alpha \equiv \frac{3}{2}$
-------------------------------------------------------

$\hat{H}(z) = \sum_{n=0}^\infty \parens{\frac{3}{2z}}^n = \frac{1}{1 -
\alpha z^{-1}} = \frac{z}{z - \alpha}$. RoC: $\set{z : \abs{z} >
\frac{3}{2}}$

When we talk about the z-transform, you can't just give an expression; you
also must provide a region of convergence. One without the other is an
incomplete picture.

Plotting region of convergence:
-------------------------------
In this case, just draw a dotted circle (radius not included), and shade
its exterior.

This is not a proof, but notice that we've got a causal signal, and a
region of convergence that is outside of some circle (and extends to
infinity). Roots of the denominator are called **poles** of the
system. Roots of the numerator are called **zeroes**. Therefore this system
has one zero and one pole.

It turns out that for right-sided functions, the RoC is always to the
outside of the radius defined by the outermost pole.

One thing I want you to pay attention to is the following: the angle of the
pole makes no difference in the region of convergence (ever!). When you
look at $\hat{H}(z) = \sum_n h(n)z^{-n}$ and replace $z = Re^{i\omega}$,
you notice that this is $\sum h(n)R^{-n}e^{-i\omega n}$. $e^{-i\omega n}$
plays no role in whether or not the kernel is absolutely summable.

So the region in the complex plane where this sum is convergent is
independent of $\omega$.

I could have made this $\alpha$ a complex number on the same radius, and
the region of convergence would have been exactly the same. It is the
magnitude of $\alpha$ that is important.

Ex: $g(n) = -\alpha^n u(-(n+1))$
--------------------------------
Notice that this is a left-sided signal.

$\hat{G}(z) = -\sum_{-\infty}^{-1} \parens{\frac{\alpha}{z}}^n =
-\sum_1^\infty \parens{\frac{\alpha}{z}}^{-n^\prime} = \frac{z}{z -
\alpha}$ ($\set{z : \abs{\alpha} > \abs{z}}$)

This is exactly the same expression in z, but the region of convergence is
different. This is why we are compelled to always consider the region of
convergence.

So two very different expressions in time yield the same expression in
their z-transforms, but the difference is in their radii of convergence.

Just as with right-sided functions, the RoC for left-sided functions is
always inside the radius defined by the innermost pole.

Monologuing
===========

With frequency response and Fourier transforms, we all knew what we were
trying to do. We were trying to decompose a signal into its constituent
frequencies. There is no such notion for the Z-transform. The whole idea of
stabilizing an unstable system when placing a system in a feedback
configuration requires the Z-transform.

Consider $\alpha^n u(n)$.

In this case, we have not specified whether $\alpha$ is inside or outside
the unit circle. The expression is exactly the same.

Let's take the first case, where $\abs{\alpha} < 1$. The region of
convergence is outside the circle of radius $\alpha$. We could consider the
DTFT then. This is a case where the region of convergence strictly includes
the unit circle. If that is true, then there is a very simple relationship
between the z-transform and the Fourier transform: we can evaluate the
z-transform on the unit circle, i.e. $z = e^{i\omega}$. It is because of
this that some people consider the z-transform to be a generalization of
the Fourier transform. However, there are functions for which we have a
Fourier transform but no z-transform.

You also know that when the RoC contains the unit circle, the time-domain
function must be absolutely summable: the z-transform looks like the
Fourier transform of $R^{-n}h(n)$. The point of $R^{-n}$ is to tame the
function.

If $\alpha$ is outside the unit circle, no such relationship exists between
the z-transform and Fourier transform, simply because there is no Fourier
transform.

Now let's consider the anti-causal case: $-\alpha^n u(-(n+1))$.

If $\alpha$ happens to be within the unit circle, the function has no
Fourier transform. But if $\alpha$ is outside the unit circle, then
the function has a Fourier transform.

So that's the relationship between the z-transform and the Fourier
transform: if the region of convergence contains the unit circle, then you
can equate them.

If $h(n) \ztrans \hat{H}(z)$, then $h(n-1) \ztrans \frac{\hat{H}(z)}
{z}$. Similarly, $h(n+1) \ztrans z\hat{H}(z)$.

There is a difference between bounded and unbounded regions of
convergence. 

We have a few minutes, so let me talk about the distinctions between causal
signals and right-sided signals (and also anticausal / left-sided).

So let's say we take a right-sided but not causal signal. Now the RoC is
outside of radius $\alpha$, but now you have to exclude $\infty.

Similarly, for left-sided signals, you'd then exclude 0.
