EE 120: Signals and Systems
===========================
April 10, 2012.
---------------
Zero-State and Zero-Input Responses
===================================
Alternate decomposition of systems that is based on whether the system is
initially at rest or not. If initially at rest, what is response due to
initial conditions, and what is response to impulse?

Example believed to be in the textbook: system described by $y(n) -
0.9 y(n-1) = x(n)$. Causal.

If the system is not at rest, technically it is not LTI. Not nonlinear,
though. It's what we call an incrementally-linear system. What
distinguishes these from linear systems is that these have non-zero
intercepts.

Turning off the input, all you've got is some nonzero initial
condition. Figure out the response as time goes forward. This is called the
zero-input response of the system (turning off the input).

What if $y(-1) = 0$, and $x(n) = u(n)$? We've got a geometric series! Or do
it the z-transform style; do the transform as we've been doing for the past
few weeks, and causality will tell you the rest. Output is $HX$. We know
how to do partial fractions and stuff. Talk about damn walls.

This response is called the zero-state response ($y_{ZSR}$), meaning the
initial state (set of initial conditions) is zero.

So you have the zero-input response plus the zero-state response as yet
another decomposition of your system.

Now we're learning about the contributions of the nonzero initial state. We
did this by splitting the response. There is actually a way to figure out
the total response using transforms: there is a transform method. Main
point of today.

Transform Method to get the Total Response
==========================================

So, the method begins by looking at the difference equation, e.g. $y(n) =
0.9 y(n-1) + x(n)$. I'm going to use the Lee & Varaiya method, and then
we'll look at it another very related method (the unilateral
Z-transform).

For starters, multiply each side by $u(n)$. So we have $y(n)u(n) =
0.9y(n-1)u(n) + x(n)u(n)$.

Then take the Z-transform of both sides (using the definition of the
Z-transform). Note that this Z-transform looks very much like the
z-transform you've seen up until now, except that it starts at zero and
goes up to infinity. This is called the unilateral z-transform of $y$.

For any causal signal, the unilateral transform is the same as the
bilateral z-transform.

With the unilateral transform, you can do it all in one go.

Laplace Transform
=================
$\hat{X}(s) \defequals \int_{-\infty}^{\infty} x(t) e^{-st} dt$, $s =
\sigma + i\omega$. Just as with the Z-transform, we do not use an inverse
transform formula. We're going to use similar methods.

Why do we even bother with this? For reasons similar to why we justified
the Z-transform, we need a comparable transform for continuous-time
systems.

Notice how the integral is actually the Fourier transform of the perturbed
("tamed") function $x(t)e^{-\sigma t}$. The radius of convergence is
defined by $\sigma = \mathrm{Re}(s)$ -- $\omega$ plays no role in
convergence.

In continuous time, there is a very nice correspondence between sidedness
of signals and the RoC in continuous-time. Easier to remember.

Once again, causality means that the RoC extends all the way to (and
includes!) infinity.

Notice that in this case, the RoC contains the $i\omega$ axis. (Conjecture,
since not yet proven in this class) As in the z-transform, this is because
$x(t)$ is a stable signal. That is, it is absolutely integrable. The proof
is fairly trivial: $\int\abs{x(t)e^{-i\omega t}} dt = \int \abs{x(t)} dt <
\infty$.

Transform pairs!

$$
\renewcommand{\Re}{\mathrm{Re}}
e^{-at} u(t) \ltrans \frac{1}{s+a} (-\Re(a) < \Re(s))
\\ -e^{-at} u(-t) \ltrans \frac{1}{s+a} (\Re(s) < -\Re(a))
$$
