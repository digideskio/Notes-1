EE 120: Signals and Systems
===========================
February 6, 2012.
-----------------

+-----+-----+------+
|DTFS |====>|CTFS  |
+-----+-----+------+
|   v=|=====|//    |
+-----+-----+------+
|DTFT |====>|CTFT  |
+-----+-----+------+

CTFS:

periodic if x(t+p) = x(t) ∃ p ∈ R. Smallest positive p is called the
fundamental period. Fundamental frequency ω₀ ≡ 2π/p.

Can also write p = 2π/ω₀. In discrete-time, writing it this way was
dangerous, since depending on ω₀, p may or may not be an integer.

For discrete-time signals, the constant signal was periodic with p=1.
x(t) = 1 ∀t ∈ Z?

What about the signal x(t) = 1 ∀t ∈ R? The fundamental period is undefined:
any p>0 can serve as a period.

So there are subtleties in each story. In the discrete-time story, there
were some sinusoids that looked periodic but weren't, and the constant
signal has no fundamental period in continuous-time.

We're going to jump immediately into the Fourier series. He said you can
decompose any continuous signal as a linear combination of complex
exponentials that are related to each other by virtue of being at
frequencies that are integer multiples of the fundamental period.

x(t) = ∑X{k}exp{ikω₀t} = ∑X{k}Ψ{k}.

We know the procedure for finding the kth coefficient. Before we go there,
there's something you ought to pay attention to in this expression. When I
draw a typical periodic signal, when I look at one period, how many points
do I have? Uncountably infinite. Also range is potentially a set of
uncountably many values. So this is a bold claim: we can represent these
with a countable number of eigenfunctions.

Unlike the discrete-time story, this equality will not always be a
pointwise equality. There are different gradations of convergence. Whenever
you have an infinite sum, you have to worry about convergence in the back
of your head. For well-behaved signals, the left and the right converge,
and this is true for every t. The less well-behaved signals will no longer
hold pointwise. Strange things happen, e.g. Gibbs phenomenon.

You'll have a reasonable understanding of Fourier series. We're not going
to worry too much about convergence in this class. The only time it doesn't
arise is in the discrete-time Fourier series.

Claim: fourier analysis works. One path we can take is for you to take my
word for it. Or we could prove it. Since last time was hilarious, we're
going to take this for granted, for now. Assume orthogonality of Ψ{k} for
some definition of the inner product. Ψ{k} = exp(ikω₀t).

I am now going to determine X{l}. Take the inner product of x with Ψ{l}.

The procedure is exactly the same. We're just swapping out our definition
of inner product. Exploit the orthogonality.

For discrete-time p-periodic signals, we defined the inner product as
〈f,g〉 = ∑fg*. Guess what the continuous-time inner product is for
p-periodic signal!

And if they're non-periodic, we'll do the same, but over all time.

Show that our eigenfunctions are orthogonal.

Synthesis equation: x(t) = ∑X{k}exp(ikω₀t)
Analysis equation:  X{k} = (1/p)∫x{k}exp(-ikω₀t).

How do I show that 〈Ψ{k}, Ψ{l}〉 = 0 k≠l? Just evaluate the integral. We
get an exponential with period p, integrated over a period p? Looks like 0
to me.

Example: X(t) = cos(πt/3). (exp(iπt/3) + exp(-iπt/3))/2. Ψ{1} = Ψ{-1} = ½.

q(t) = ∑δ(t-ℓp) = ∑Q{k}exp(ikω₀t)
δ(t) = du(t)/dt

Poisson's identity. ∑δ(t-ℓp) = (1/p)∑exp(ikω₀t)

R{k} = (1/p)∫r(k)exp(-ikω₀t) = 1/p if k=0 else sin(kω₀Δ/2)/(pkπΔ/2)

What happens if I want to approximate a signal that has finite energy? What
should the coefficients α{k} be?

orthogonal projection! Least squares!
