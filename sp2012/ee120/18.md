EE 120: Signals and Systems
===========================
March 22, 2012.
--------------
Upsampling property
===================
$$
x(n) \mapsto \uparrow N \mapsto y(n) = \begin{cases}
x(n/N) & \text{if } n \equiv 0 (\mod N)
\\ 0 & \rm{e/w}
\end{cases}
$$

i.e. we have the same values, but now interspersed with more zeroes. Take
the axis and dilate by three. So see if you can come up with an expression
for the Z-transform of the upsampled signal. We should just have
$\hat{X}(z^N)$.

This should not surprise you. When you upsampled in the time domain, what
happened in frequency? We contracted in the frequency domain. You get that
even from here. If I remind you of an example we did eons ago, $y(n) =
\alpha y(n-1) + x(n)$ had a frequency response of $G(\omega) = \frac{1}{1 -
\alpha e^{-i\omega}}$. If I change this to the parameters of $y(n) = \alpha
y(n-N) + x(n)$, $H(\omega) = \frac{1}{1 - \alpha e^{i\omega N}}$. But if you
compare $g(n) = \alpha^n u(n)$ with $h(n) = \alpha^{nN} u(n)$, we've
already seen this.

So when you upsample, you have the $z$ raised to the $n^{th}$ power.

What's the RoC? Should bring up two more questions: what happens to the
poles and zeroes? We take the $n^{th}$ root of everything (i.e. the inverse
function), so everything moves closer to 1. (rationale: $z_p^N = p \implies
z_p = ?$. We get $N$ times as many poles, in fact, since we have $N$ roots
of $p$. ibid for zeros.

Going back to the question for the region of convergence for y: if the RoC
for x is $R_1 < \abs{z} < R_2$, the RoC for y is $R_1 < \abs{z}^N < R_2$,
so $R_y = R_x^{1/N}$.

So let's do the example given earlier: $y(n) = \alpha y(n-N) + x(n)$.
$\hat{H}_1(z) = \frac{1}{1 - \alpha z^{-1}}$. $\hat{H}_4 = \frac{1}{1 -
\alpha z^{-4}}$. Draw pole-zero diagrams, region of convergence?

(note that we've got degeneracy -- multiplicity. Must denote with a number
in parentheses if you've got multiplicity greater than 2; if multiplicity
is 2, you can use a double-circle or double-x).

Differentiation
===============
Another property that's actually very important is differentiation in Z. So
suppose you've transformed $x \ztrans \hat{X}(z)$. What is $\deriv{\hat{X}}
{z}$? $-z\deriv{\hat{X}}{z} \ztrans n x(n)$.

Example:
--------
$g(n) = n\alpha^n u(n) \ztrans \hat{G}(z) = ?$

If you want to make this look like the original form, just multiply top and
bottom by $z^{-2}$. Very important point: extension to higher derivatives.

So what happens as we increase this? What does this mean?

We can decompose any rational z transform into a linear composition of
lower-order terms. Fundamental theorem of algebra. Proposition: suppose
we've got a transfer function. We've got a numerator over a denominator. We
can factor the numerator and denominator. You also learned that whenever
you do this, you can break apart the ratio in terms of a sum.

Note that this starts breaking when you have degeneracy (i.e. systems with
duplicate poles). So from this qualitative argument, it should not surprise
you if I tell you that the only way you can get a rational Z-transform is
if the system is the sum of one-sided exponentials multiplied by
some polynomial.

We'd also have to include the left-sided versions of these.

We can make a general statement: a Z-transform expression $\hat{X}(z)$ is
rational iff x(n) is a linear combination of terms $n^k \alpha^n u(n)$,
$n^k\beta^n u(-n)$. Shifted versions will certainly also work.

Using partial fractions is one of the methods of doing an inverse
transform. We're not going to learn a formal inverse Z-transform; we're
just going to use various heuristics (not unlike solving differential
equations).

In general, the inverse z-transform requires a contour integral (complex
analysis) and thus is not a required in this class.

Now, if you believe this, we've got several things: $n^k\alpha^n u(n)$,
LCCDEs, and rational Z-transforms. They form a family.

LCCDEs and Rational Z Transforms
================================

Suppose I've got an input, an impulse response, and an output. You know
this is a convolution of x and h, so $\hat{Y} = \hat{X}\hat{Z}$, which
means the transfer function of an LTI system is the ratio of the transform
of the output to the transform of the input (for LTI systems).

Frequency response of the filter gives you the Fourier transform of the
output.

We can write our difference equation as $\sum_{k=0}^N a_k y(n-k) = \sum_m^M
b_m x(n-m)$. We've seen this.

One way to get the transfer function is to take the z-transforms of both
sides. If they're equal in the time domain, their z-transforms must also be
equal in the frequency domain. Time-shift property. Just considering the
ratio $\hat{H} \equiv \frac{\hat{Y}}{\hat{X}}$, we have our transfer
function.

Familiarize yourself with going from the LCCDE to the transfer function by
inspection.

Now, for the end of the lecture: irrational Z-transform.

Example
-------

This is a standard example in practically any signal-processing book you'll
find. $\hat{X} = \log(1 + \alpha z^{-1}$. Determine $x(n)$.

(differentiation property)

($\frac{(-1)^{n-1} \alpha^n}{n}u(n-1)$)

You can also use (to check) Taylor expansion centered at 1: $\log(1 +
\lambda) = \sum_{n=1}^\infty \frac{(-1)^{n+1} \lambda^n}{n}$.
