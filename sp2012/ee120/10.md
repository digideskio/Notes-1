EE 120: Signals and Systems
===========================
February 21, 2012.
-----------------

Circular convolution wrap-up
============================

h(n) = B/πn sin(An) ⇐F⇒ H(ω) = u(n+A)-u(n-A).
(ideal low-pass filter and its impulse response)

What if I had a filter whose frequency response G(ω) is basically the
signal (circularly) convolved with itself (with some extra factors)?
description: ramp going from 0 to 4AB² from -2A to 0, then back down to 0.

* Recall: To perform circular convolution:
  + Keep one function fixed (in terms of a dummy frequency variable)
  + Keep only one period of the other signal.
  + Perform regular convolution.

* Example: (Q * R)(ω).
  + Plot on a dummy-variable axis Q(λ) with its replicas.
  + Plot R only in one period (zero out all replicas).
  + Flip & slide R. R(λ-ω)

What's the brute-force way to find the impulse response? Synthesis
equation.

Inspection method? It looks like it's 2πh²(n) = 2B²sin²(An)/πn² (circular
convolution must yield the 2π scalar)

* Recall: q(n)r(n) ⇐F⇒ 2π (Q*R)(ω).

* _Note: this filter is BIBO stable, and its Fourier transform is continuous._

Now, we can spend a lot of time on the various properties of the DTFT (what
happens when you time-reverse a signal, shift, multiplication properties,
modulation, etc.), and this'll probably show up in a problem set.

As the last example on the DTFT: f(n) = e^{iω₀n}h(n). Let one of these be a
sinusoid. What do you do?

It's effectively shifted by ω₀, after the math clears.

**Intermission**
================
Tentative midterm date: March 13.

Continuous-Time Fourier Transform
=================================

X(ω): roughly the frequency response in continuous-time.

	X(ω) = ∫x(t)e^{-iωt}dt
	x(t) = (1/2π) ∫X(ω)e^{iωt}dω

Slight shorthand:
X = ∫x(τ)φ{τ} dτ (φ{t}(ω) ≙ e^{-iωτ})

To determine x(t): (assume for now that 〈φ{τ}, φ{t}〉 = δ{τt})

〈X, φ{t}〉 ≙ ∫X)ω) φ{t}*(ω) dω.

〈X,φ{t}〉 = ∫X〈φ{τ},φ{t}〉dτ

_NB: Inner products are in frequency domain._

* Recall:
  + In the discrete-time case, we found that for 〈φ{m},φ{n}〉, we got
	2πδ{mn}. Turns out, we have exactly the same relationship in the
	continuous-time case.
  + In the continuous-time case, we have 2πδ(m-n).

* Recall Poisson's identity: ∑δ(t-ℓp) = (1/p)∑exp(ikω₀t).

Now we are desperate to have ∫e^{iωt}dω = 2πδ(t). Which means we must have
δ(t) ≡ 1/2π ∫e^{iωt}dω. New definition for δ(x).

Mutual orthogonality of the CTFT takes on this nasty form.

Plausibility argument:
----------------------

The right-hand side is proportional to ∫e^{iωt}dω = ∫cos(ωt)̣dω +
i∫sin(ωt)dω. Imaginary part is guaranteed to be 0. By the same argument,
the cosine portion is 0 if t ≠ 0. Otherwise, we're integrating 1 over all
reals, so we have ∞.

Constructively interfere at t = 0, but destructively interfere at t ≠ 0.

Therefore the right-hand side must be proportional to δ(t).

The claim is that the constant of proportionality is 2π. The hard part is
to recognize this is actually a Dirac delta.

**Intermission**
================

Steam coming out of our heads, evidently. Remember, this is the only
barrier to studying the DTFT.

One way to show δ(t) ≡ 1/2π ∫e^{iωt}dω
======================================

This method you will see, hear, etc. in engineering contexts for figuring
out something that doesn't converge, since Riemann integrals don't really
work here.

δ{Δ}(t) = 1/2π ∫e^{iωt}e^{-Δ|ω|}. This product is supposed to tame the
function such that it is now integrable.

(take Δ > 0)

Multiply what you've got with something that makes the product
converge. Then take the limit as said function goes to 1?

In other words, I am perturbing the problem slightly to make it stable and
taking the limit as stability goes to 0.

NB: half-width, half-maximum: where we're at half the width of our function
and also half the maximum value.

Perturbation theory!

α ≡ perturbation parameter. Chosen such that area is 1.

Result of the integral: δ{Δ}(t) = Δα/π 1/(Δ² + t²). Turns out α=1.

This is a Cauchy probability density function.

(names for dirac delta: generalized function, distribution. Look up theory
 of distributions)
